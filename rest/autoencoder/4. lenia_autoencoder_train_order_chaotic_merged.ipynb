{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVaoUuG8w-T",
        "outputId": "ef961d0d-080e-4b21-ed59-032a979a9474"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_merged | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzMOr2sCFgiQ",
        "outputId": "60f55fa6-007f-4687-8158-118c12659206"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import random\n",
        "\n",
        "# def delete_random_files(folder_path, num_files):\n",
        "#     # Get a list of all the files in the folder\n",
        "#     files = os.listdir(folder_path)\n",
        "#     # Shuffle the list of files randomly\n",
        "#     random.shuffle(files)\n",
        "#     # Loop over the shuffled list and delete the first num_files files\n",
        "#     for filename in files[:num_files]:\n",
        "#         # Get the full path of the file\n",
        "#         file_path = os.path.join(folder_path, filename)\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         # print(f\"Deleted file: {file_path}\")\n",
        "\n",
        "# # Example usage\n",
        "# folder_path = \"/content/drive/MyDrive/lenia_dataset\"\n",
        "# num_files_to_delete = 6950\n",
        "# delete_random_files(folder_path, num_files_to_delete)\n"
      ],
      "metadata": {
        "id": "wKcYc9yuUp6m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_merged | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amFIjYiRU91m",
        "outputId": "9b1f6aa4-f426-4623-cd0c-ce3d208c0fdb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the path to the folder containing the images\n",
        "folder_path = \"/content/drive/MyDrive/lenia_merged/\"\n",
        "\n",
        "# Initialize lists to hold the image data and labels\n",
        "data = []\n",
        "\n",
        "# Loop over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(os.path.join(folder_path, filename))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image to a fixed size\n",
        "    resized = cv2.resize(gray, (28, 28))\n",
        "    # Add the image data to the list\n",
        "    data.append(resized)\n",
        "    # Add the label to the list\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "data = np.array(data)\n",
        "\n",
        "# Split the data into training and testing sets\n"
      ],
      "metadata": {
        "id": "PVrlDRbAR1DM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest = train_test_split(data, test_size=0.3, random_state=2)\n"
      ],
      "metadata": {
        "id": "hxKS-k9PachM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = xtrain.reshape(xtrain.shape[0], 28, 28, 1)\n",
        "X_test = xtest.reshape(xtest.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "hVnVmgFoak-7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.layers import Layer\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, add\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "o4HDmElbT3vW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(\"float32\")/255.\n",
        "X_test = X_test.astype(\"float32\")/255.\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_NV0yoUYFJ",
        "outputId": "e4eb7904-ca85-44ac-b884-11da0aed1072"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (359, 28, 28, 1)\n",
            "359 train samples\n",
            "154 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
      ],
      "metadata": {
        "id": "AIAPAmWQeiCn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 64\n",
        "output_size = 784"
      ],
      "metadata": {
        "id": "bUUrrS5BemKx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h = Dense(hidden_size, activation='relu')(x)\n",
        "r = Dense(output_size, activation='sigmoid')(h)\n",
        "\n",
        "autoencoder = Model(inputs=x, outputs=r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "NZ1kOsbaerAl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "Elx0KmSuesZL",
        "outputId": "3ac5b7e5-ba01-4f96-de0e-3514d2ee400f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"191pt\" height=\"255pt\" viewBox=\"0.00 0.00 143.00 191.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-187 139,-187 139,4 -4,4\"/>\n<!-- 140528017784544 -->\n<g id=\"node1\" class=\"node\">\n<title>140528017784544</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-146.5 0,-182.5 135,-182.5 135,-146.5 0,-146.5\"/>\n<text text-anchor=\"middle\" x=\"29\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">input_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"58,-146.5 58,-182.5 \"/>\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n</g>\n<!-- 140528017783536 -->\n<g id=\"node2\" class=\"node\">\n<title>140528017783536</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"19,-73.5 19,-109.5 116,-109.5 116,-73.5 19,-73.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"66,-73.5 66,-109.5 \"/>\n<text text-anchor=\"middle\" x=\"91\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 140528017784544&#45;&gt;140528017783536 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140528017784544-&gt;140528017783536</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-146.31C67.5,-138.29 67.5,-128.55 67.5,-119.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-119.53 67.5,-109.53 64,-119.53 71,-119.53\"/>\n</g>\n<!-- 140526573911392 -->\n<g id=\"node3\" class=\"node\">\n<title>140526573911392</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-0.5 12,-36.5 123,-36.5 123,-0.5 12,-0.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"73,-0.5 73,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"98\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 140528017783536&#45;&gt;140526573911392 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140528017783536-&gt;140526573911392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-73.31C67.5,-65.29 67.5,-55.55 67.5,-46.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-46.53 67.5,-36.53 64,-46.53 71,-46.53\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 128\n",
        "\n",
        "history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bXE6xFXet1a",
        "outputId": "26928a7c-3d3c-458b-ab5b-94feca12ffeb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 0.1056 - val_loss: 0.1031\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.1010 - val_loss: 0.0978\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0947 - val_loss: 0.0901\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0867 - val_loss: 0.0819\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0786 - val_loss: 0.0741\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0709 - val_loss: 0.0673\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0645 - val_loss: 0.0616\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0590 - val_loss: 0.0567\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0542 - val_loss: 0.0523\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0497 - val_loss: 0.0482\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0456 - val_loss: 0.0444\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0417 - val_loss: 0.0408\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0381 - val_loss: 0.0376\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0350 - val_loss: 0.0348\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0321 - val_loss: 0.0322\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0297 - val_loss: 0.0299\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0275 - val_loss: 0.0278\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0256 - val_loss: 0.0260\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0238 - val_loss: 0.0243\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0223 - val_loss: 0.0228\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0209 - val_loss: 0.0215\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0197 - val_loss: 0.0203\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0187 - val_loss: 0.0193\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0169 - val_loss: 0.0177\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0162 - val_loss: 0.0170\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0155 - val_loss: 0.0163\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0149 - val_loss: 0.0158\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0144 - val_loss: 0.0152\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0139 - val_loss: 0.0147\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0134 - val_loss: 0.0142\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0129 - val_loss: 0.0138\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0125 - val_loss: 0.0134\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0121 - val_loss: 0.0130\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0118 - val_loss: 0.0126\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0114 - val_loss: 0.0123\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0111 - val_loss: 0.0120\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0108 - val_loss: 0.0118\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0106 - val_loss: 0.0115\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 0.0112\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0101 - val_loss: 0.0110\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0098 - val_loss: 0.0108\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0096 - val_loss: 0.0106\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0094 - val_loss: 0.0104\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0092 - val_loss: 0.0102\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0090 - val_loss: 0.0100\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0088 - val_loss: 0.0099\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0087 - val_loss: 0.0097\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0085 - val_loss: 0.0095\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0084 - val_loss: 0.0094\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0082 - val_loss: 0.0093\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0081 - val_loss: 0.0091\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.0080 - val_loss: 0.0090\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0078 - val_loss: 0.0089\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0077 - val_loss: 0.0088\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0076 - val_loss: 0.0087\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0075 - val_loss: 0.0086\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0074 - val_loss: 0.0085\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0073 - val_loss: 0.0084\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0072 - val_loss: 0.0083\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0071 - val_loss: 0.0082\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0070 - val_loss: 0.0081\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0069 - val_loss: 0.0080\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0069 - val_loss: 0.0079\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0068 - val_loss: 0.0079\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0067 - val_loss: 0.0078\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.0077\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0065 - val_loss: 0.0076\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0063 - val_loss: 0.0073\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0062 - val_loss: 0.0073\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0062 - val_loss: 0.0072\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0061 - val_loss: 0.0071\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.0071\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0070\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0059 - val_loss: 0.0070\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0059 - val_loss: 0.0069\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0068\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0058 - val_loss: 0.0068\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0057 - val_loss: 0.0067\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0067\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0066\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0056 - val_loss: 0.0066\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0055 - val_loss: 0.0065\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0055 - val_loss: 0.0065\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0054 - val_loss: 0.0064\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0054 - val_loss: 0.0064\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0053 - val_loss: 0.0063\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.0063\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0053 - val_loss: 0.0062\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0052 - val_loss: 0.0062\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0052 - val_loss: 0.0061\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0051 - val_loss: 0.0061\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0051 - val_loss: 0.0061\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0051 - val_loss: 0.0060\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0060\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0050 - val_loss: 0.0059\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0049 - val_loss: 0.0059\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.0058\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.0058\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0048 - val_loss: 0.0058\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0048 - val_loss: 0.0057\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0048 - val_loss: 0.0057\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0045 - val_loss: 0.0054\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0054\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0053\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0044 - val_loss: 0.0053\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0044 - val_loss: 0.0053\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0052\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0052\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0043 - val_loss: 0.0052\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0043 - val_loss: 0.0051\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0043 - val_loss: 0.0051\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0042 - val_loss: 0.0051\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0042 - val_loss: 0.0050\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0050\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0042 - val_loss: 0.0050\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0049\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0049\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0041 - val_loss: 0.0049\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0047\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0047\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0039 - val_loss: 0.0046\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0046\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0046\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0038 - val_loss: 0.0045\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0045\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0045\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0037 - val_loss: 0.0045\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0035 - val_loss: 0.0042\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.0039\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0032 - val_loss: 0.0039\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0032 - val_loss: 0.0038\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0036\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0035\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0028 - val_loss: 0.0034\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0033\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0033\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0028 - val_loss: 0.0033\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0028 - val_loss: 0.0033\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0033\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0027 - val_loss: 0.0033\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0027 - val_loss: 0.0032\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0026 - val_loss: 0.0032\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0024 - val_loss: 0.0029\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0023 - val_loss: 0.0028\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0022 - val_loss: 0.0027\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.0026\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.0025\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.0024\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0018 - val_loss: 0.0022\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0017 - val_loss: 0.0021\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0017 - val_loss: 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder = Model(x, h)\n",
        "encoded_imgs = conv_encoder.predict(X_test)\n",
        "\n",
        "n = 1\n",
        "plt.figure(figsize=(28, 10))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 16).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "QLmpqHMBevu5",
        "outputId": "f42267d2-a89e-4163-c02d-613be13662ca"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExA7kO63eyvD",
        "outputId": "266d2c56-47eb-4994-b680-57cda30f2b08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "plt.figure(figsize=(28, 28))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28),cmap=\"gist_earth\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "SSiPSKeNfgce",
        "outputId": "8f3acd80-a16e-47c1-b560-1eb4ebb39838"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(28,28))\n",
        "for i in range(n):    \n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i+n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap=\"gist_earth\")\n",
        "    # plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tOLD93oKgHb3",
        "outputId": "8e3bd273-bcda-467b-c34c-935bb957cad4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "pJ9a9Kp2fiPO",
        "outputId": "268de68b-7a38-4d0b-f092-3ef4b0a13ffe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "i=99\n",
        "print(\"Error or loss for the image \"+str(i))\n",
        "print(tf.math.reduce_mean(tf.square(decoded_imgs[i].reshape(28, 28)-X_test[i].reshape(28, 28))))\n",
        "print(\"------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65L7IaM-foed",
        "outputId": "1bfd9599-af5f-4910-c1bd-a898cd175405"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error or loss for the image 99\n",
            "tf.Tensor(0.0019800924, shape=(), dtype=float32)\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wbaHstUEr_AA"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}