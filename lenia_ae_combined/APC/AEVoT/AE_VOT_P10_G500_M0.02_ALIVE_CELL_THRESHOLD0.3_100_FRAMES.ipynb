{"cells":[{"cell_type":"markdown","source":["# **P10|G500|M0.02|ALIVE_CELL_THRESHOLD0.3|100_FRAMES**"],"metadata":{"id":"roWwEXQEaEvs"}},{"cell_type":"markdown","metadata":{"id":"P7fqTIpzHNXe"},"source":["# 1. Creating 'n' random (using random kernels) lenia images \"meaningful\" Dataset for AutoEncoder training procedure"]},{"cell_type":"markdown","metadata":{"id":"x7RYfMBHH20E"},"source":["### For example generating 100 frames each gif, let us just save 10000 images by calling 100 random kernels. As we generate 100 frames each simulation, we just need 100 random simulations for 100 random kernels which produces 100*100=10000 images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MO_V_gWcW4qy"},"outputs":[],"source":["!conda install -y ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_p7V-7_KW4qz"},"outputs":[],"source":["!conda install -y opencv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kWISxBxW4qz"},"outputs":[],"source":["!conda install -y keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zLdBZljJW4qz"},"outputs":[],"source":["!conda install -y tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0m6LbbmW4qz"},"outputs":[],"source":["!conda install -y -c conda-forge python-flatbuffers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8RKk2WmhW4q0"},"outputs":[],"source":["!conda install -y pydot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usGU116mW4q0"},"outputs":[],"source":["!pip install pydot graphviz"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"LKn7K0gJW4q0"},"outputs":[],"source":["!ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZD98te7C6Qk"},"outputs":[],"source":["dataset_size = 30\n","# Imports\n","# https://chakazul.github.io/Lenia/JavaScript/Lenia.html\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import time\n","import warnings\n","warnings.simplefilter(\"ignore\", UserWarning)\n","#Imports\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation\n","import scipy.signal\n","import os.path\n","import os\n","from datetime import datetime\n","from json import JSONEncoder\n","import json\n","from pathlib import Path\n","                \n","\n","OUTPUT_PATH = './outputs'\n","\n","mu = 0.31\n","sigma = 0.057\n","dt = 0.1\n","\n","\n","frames = 100\n","\n","\n","\n","class Lenia:\n","    def __init__(self, kernel, board):\n","        self.sigma = sigma\n","        self.mu = mu\n","        self.dt = dt\n","        self.kernel = kernel\n","        self.normalise_kernel()\n","        self.frames = frames\n","        self.anim = None\n","        self.lenia_board_state = {}\n","        self.frame_intervals = 10\n","        # For random initialisation\n","        self.board = board\n","        self.cmap = 'viridis'\n","        self.fig, self.img = self.show_board()\n","        \n","\n","    # FLEXIBLITY TO CHANGE GROWTH FUNCTION\n","    def growth_function1(self, U:np.array):\n","        gaussian = lambda x, m, s: np.exp(-( (x-m)**2 / (2*s**2) ))\n","        return gaussian(U, self.mu, self.sigma)*2-1\n","\n","\n","    def show_board(self, \n","                   display:bool=False,\n","                   ):\n","        dpi = 50 # Using a higher dpi will result in higher quality graphics but will significantly affect computation\n","\n","        self.fig = plt.figure(figsize=(10*np.shape(self.board)[1]/dpi, 10*np.shape(self.board)[0]/dpi), dpi=dpi)\n","\n","        ax = self.fig.add_axes([0, 0, 1, 1])\n","        ax.axis('off')\n","        \n","        self.img = ax.imshow(self.board, cmap=self.cmap, interpolation='none', aspect=1, vmin=0) #  vmax=vmax\n","        \n","        if display:\n","            plt.show()\n","        else: # Do not show intermediate figures when creating animations (very slow)\n","            plt.close()\n","\n","        return self.fig, self.img\n","    \n","    \n","    def animate(self):\n","        \n","        self.anim =  matplotlib.animation.FuncAnimation(self.fig, self.animate_step, \n","                                            frames=self.frames, interval=self.frame_intervals, blit=True)\n","\n","    \n","    def animate_step(self, i:int) -> plt.imshow:\n","        neighbours = scipy.signal.convolve2d(self.board, self.kernel, mode='same', boundary='wrap')\n","        self.board = np.clip(self.board + self.dt * self.growth_function1(neighbours), 0, 1)\n","        if (i+1) % 10 == 0:\n","            self.record_board_state(i)\n","        self.img.set_array(self.board) # render the updated state \n","        return self.img,\n","\n","    def save_animation(self, dir, \n","                       filename:str,\n","                       ):\n","        if not self.anim:\n","            raise Exception('ERROR: Run animation before attempting to save')\n","            return \n","        output_path = OUTPUT_PATH+\"/\"+dir\n","        Path(output_path).mkdir(parents=True, exist_ok=True)\n","        fmt = os.path.splitext(filename)[1] # isolate the file extension\n","        \n","        if fmt == '.gif':\n","            f = os.path.join(output_path, filename) \n","            writer = matplotlib.animation.PillowWriter(fps=30) \n","            self.anim.save(f, writer=writer)\n","        else:\n","            raise Exception('ERROR: Unknown save format. Must be .gif or .mp4')\n","        # writer.close()\n","\n","    \n","    def normalise_kernel(self) -> np.array:\n","\n","        kernel_norm = self.kernel / (1*np.sum(self.kernel))\n","        self.norm_factor = 1/ (1*np.sum(self.kernel))\n","        self.kernel = kernel_norm \n","        return kernel_norm\n","        \n","        \n","    def plot_kernel_info(self,\n","                         dir,\n","                         cmap:str='viridis', \n","                         bar:bool=False,\n","                         save:str=None,\n","                         ) -> None:\n","\n","        \n","        k_xsection = self.kernel[self.kernel.shape[0] // 2, :]\n","        k_sum = np.sum(self.kernel)\n","        \n","        fig, ax = plt.subplots(1, 3, figsize=(14,2), gridspec_kw={'width_ratios': [1,1,2]})\n","        \n","        # Show kernel as heatmap\n","        ax[0].imshow(self.kernel, cmap=cmap, vmin=0)\n","        ax[0].title.set_text('Kernel')\n","        \n","        # Show kernel cross-section\n","        ax[1].title.set_text('Kernel Cross-section')\n","        if bar==True:\n","            ax[1].bar(range(0,len(k_xsection)), k_xsection, width=1)\n","        else:\n","            ax[1].plot(k_xsection)\n","        \n","        # Growth function\n","        ax[2].title.set_text('Growth Function')\n","        x = np.linspace(0, k_sum, 1000)\n","        ax[2].plot(x, self.growth_function1(x))\n","        \n","        if save:\n","            output_path = OUTPUT_PATH+\"/\"+dir\n","            Path(output_path).mkdir(parents=True, exist_ok=True)\n","            print('Saving kernel and growth function info to', os.path.join(output_path, 'kernel_info'))\n","            \n","            plt.savefig(os.path.join(output_path, 'kernel_info.png') )\n","\n","\n","    def run_simulation(self, generation) -> None:\n","        self.animate()\n","        sub_dir = generation+\"/\"+str(datetime.now())\n","        outfile = \"output\"+str(datetime.now())+\".gif\"   \n","        print('./folder/{}...)'.format(sub_dir))\n","        \n","        self.save_animation(sub_dir, outfile)\n","        self.plot_kernel_info(dir=sub_dir, save=True)\n","        return self.lenia_board_state\n","\n","\n","    def record_board_state(self, i):\n","        board_arr = self.board.flatten()\n","        board_val_greater_than_point_five = list(board_arr[board_arr > 0.5])\n","        self.lenia_board_state[\"frame_\"+str(i+1)] = len(board_val_greater_than_point_five)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D72QJVKKKRce"},"outputs":[],"source":["kernel_size = 16\n","board_size = 64\n","def random_kernel_generator():\n","    grid = np.random.rand(kernel_size, kernel_size)\n","    grid = np.round(grid, 3)\n","    return grid\n","def random_board_generator():\n","    board = np.random.rand(board_size, board_size)\n","    board = np.round(board, 3)\n","    return board\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pk3emCUvMW4V"},"outputs":[],"source":["\n","!rm -rf outputs\n","!rm -rf sample_data\n","!rm *.png\n","!rm *.gif\n","for i in range(dataset_size):\n","  board = random_board_generator()\n","  lenia = Lenia(random_kernel_generator(), random_board_generator())\n","  board_alive_cell = lenia.run_simulation(\"certain_files\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4raYHf0SxfV"},"outputs":[],"source":["!mv /home/ec2-user/SageMaker/outputs/*/*/*.gif /home/ec2-user/SageMaker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlfrPuvpW4q3"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9yoTriLThZm"},"outputs":[],"source":["!rm -rf outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_OPSu6wW4q4"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlmR0K3yW4q4"},"outputs":[],"source":["!rm -rf 2.lost+found"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCmLrHPTW4q4"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5l4-Iz5EUDFi","scrolled":true},"outputs":[],"source":["!i=1; for file in *.gif; do mv \"$file\" \"$(printf '%d' $i).${file##*.}\"; ((i++)); done\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Odj5slwFW4q5"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IaAXCQJ4UsYF"},"outputs":[],"source":["!for file in *.gif; do ffmpeg -i \"$file\" \"${file%.*}-%d.jpg\"; done\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLHXw_EHU9ui"},"outputs":[],"source":["!rm *.gif\n","!rm *.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqMb1BvEVM6K"},"outputs":[],"source":["!i=1; for file in *.jpg; do mv \"$file\" \"$(printf '%d' $i).${file##*.}\"; ((i++)); done\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnwyHEA7VP_-"},"outputs":[],"source":["!mkdir dataset\n","!mv *.jpg dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M6Nj9ShN2FNs"},"outputs":[],"source":["!ls /home/ec2-user/SageMaker/dataset | wc -l\n"]},{"cell_type":"markdown","metadata":{"id":"larlNbea2bmT"},"source":["# 2. AutoEncoder procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oL0ol38G2WQm"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Set the path to the folder containing the images\n","folder_path = \"/home/ec2-user/SageMaker/dataset/\"\n","\n","# Initialize lists to hold the image data and labels\n","data = []\n","\n","# Loop over the files in the folder\n","for filename in os.listdir(folder_path):\n","    # Load the image using OpenCV\n","    img = cv2.imread(os.path.join(folder_path, filename))\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Resize the image to a fixed size\n","    resized = cv2.resize(gray, (28, 28))\n","    # Add the image data to the list\n","    data.append(resized)\n","    # Add the label to the list\n","\n","# Convert the lists to numpy arrays\n","data = np.array(data)\n","\n","# Split the data into training and testing sets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vL1WXZm2sR5"},"outputs":[],"source":["xtrain, xtest = train_test_split(data, test_size=0.3, random_state=2)\n","\n","     \n","\n","X_train = xtrain.reshape(xtrain.shape[0], 28, 28, 1)\n","X_test = xtest.reshape(xtest.shape[0], 28, 28, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6-yRLEP2sh-"},"outputs":[],"source":["import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from keras.layers import Layer\n","from keras.datasets import mnist\n","from keras.models import Model\n","from keras.layers import Input, add\n","from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n","from keras import regularizers\n","from keras.regularizers import l2\n","from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n","from keras.utils import np_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcAT9edS2vt9"},"outputs":[],"source":["X_train = X_train.astype(\"float32\")/255.\n","X_test = X_test.astype(\"float32\")/255.\n","\n","print('X_train shape:', X_train.shape)\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBqY6ZXy2xBg"},"outputs":[],"source":["X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n","X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmO-eYNG2zhX"},"outputs":[],"source":["input_size = 784\n","hidden_size = 36\n","output_size = 784"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LROcoTh22Vd"},"outputs":[],"source":["x = Input(shape=(input_size,))\n","h = Dense(hidden_size, activation='relu')(x)\n","r = Dense(output_size, activation='sigmoid')(h)\n","\n","autoencoder = Model(inputs=x, outputs=r)\n","autoencoder.compile(optimizer='adam', loss='mse')\n","     \n","\n","from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","\n","\n","# SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zL3INWSn25Hg"},"outputs":[],"source":["epochs = 300\n","batch_size = 128\n","\n","history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, X_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LSOI75h4285k"},"outputs":[],"source":["conv_encoder = Model(x, h)\n","encoded_imgs = conv_encoder.predict(X_test)\n","\n","n = 1\n","plt.figure(figsize=(28, 10))\n","for i in range(n):\n","    ax = plt.subplot(1, n, i+1)\n","    plt.imshow(encoded_imgs[i].reshape(6, 6).T)\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZFgvYsq3DyK"},"outputs":[],"source":["decoded_imgs = autoencoder.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7fFK0wy3Hdu"},"outputs":[],"source":["n = 1\n","plt.figure(figsize=(28, 28))\n","for i in range(n):\n","    # display original\n","    ax = plt.subplot(3, n, i+1)\n","    plt.imshow(X_test[i].reshape(28, 28),cmap=\"gist_earth\")\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKLdtYan3T4p"},"outputs":[],"source":["plt.figure(figsize=(28,28))\n","for i in range(n):    \n","    # display reconstruction\n","    ax = plt.subplot(3, n, i+n+1)\n","    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap=\"gist_earth\")\n","    # plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"itszC5wu3Vyx"},"outputs":[],"source":["print(history.history.keys())\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyVITyA83Y2O"},"outputs":[],"source":["\n","import tensorflow as tf\n","i=99\n","print(\"Error or loss for the image \"+str(i))\n","print(tf.math.reduce_mean(tf.square(decoded_imgs[i].reshape(28, 28)-X_test[i].reshape(28, 28))))\n","print(\"------------------------------------------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2SJgpRD3a2t"},"outputs":[],"source":["autoencoder.summary()"]},{"cell_type":"markdown","metadata":{"id":"N_ldz0sH4XiF"},"source":["# 3. Test the model with any random lenia board state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wK9mbRIH3rwm"},"outputs":[],"source":["# Check for orderly image reconstruction loss\n","# !wget https://dl3.pushbulletusercontent.com/pVIOI0eH0xLUqrczqileIhK0fUO5n0OL/order.jpg\n","!wget https://dl3.pushbulletusercontent.com/r8r00OkVim4UwQEyqEG5diLnZWNni1e4/order.jpg\n","from IPython.display import Image\n","Image(\"order.jpg\",width = 256, height = 256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n65NxlKT3wyt"},"outputs":[],"source":["# Check for orderly image reconstruction loss\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Set the path to the folder containing the images\n","folder_path = \"./\"\n","\n","# Initialize lists to hold the image data and labels\n","data = []\n","\n","filename = \"order.jpg\"\n","# Load the image using OpenCV\n","img = cv2.imread(os.path.join(folder_path, filename))\n","# Resize the image to a fixed size\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","resized = cv2.resize(gray, (28, 28), interpolation=cv2.INTER_AREA)\n","# Add the image data to the list\n","data.append(resized)\n","# Add the label to the list\n","\n","# Convert the lists to numpy arrays\n","data = np.array(data)\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSebcv1B3zmJ"},"outputs":[],"source":["\n","# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(data[0])\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPc1DXGR31LS"},"outputs":[],"source":["\n","predicted_order_image = autoencoder.predict(data[0].reshape(1,784))\n","print(predicted_order_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fW4LbwfI32ol"},"outputs":[],"source":["# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(predicted_order_image.reshape(28,28))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pskZ5oDU36ae"},"outputs":[],"source":["# # RECONSTRUCTION LOSS\n","# import tensorflow as tf\n","# print(tf.math.reduce_mean(predicted_order_image.reshape(28,28)-tf.square(data[0].reshape(28,28))).numpy())\n","import tensorflow as tf\n","print(\"recon loss MSE\")\n","import numpy as np\n","\n","# assuming original_img and reconstructed_img are numpy arrays of shape (28, 28)\n","mse = np.mean((-data[0].reshape(28,28) + predicted_order_image.reshape(28,28))**2)\n","print(mse)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QoEBLiyt38vY"},"outputs":[],"source":["# Check for chaotic image reconstruction loss\n","# !wget https://dl3.pushbulletusercontent.com/JMja0JFwu2M2r1A2XFKJUhj2d049mh28/chaotic.jpg\n","!wget https://dl3.pushbulletusercontent.com/HiHs0WSO0K8cEiYGfeWPeW0Q5MDGkmCs/chaotic.jpg\n","from IPython.display import Image\n","Image(\"chaotic.jpg\",width = 256, height = 256)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFWdFxuV3_xp"},"outputs":[],"source":["# Check for orderly image reconstruction loss\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Set the path to the folder containing the images\n","folder_path = \"./\"\n","\n","# Initialize lists to hold the image data and labels\n","data = []\n","\n","filename = \"chaotic.jpg\"\n","# Load the image using OpenCV\n","img = cv2.imread(os.path.join(folder_path, filename))\n","# Resize the image to a fixed size\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","resized = cv2.resize(gray, (28, 28), interpolation=cv2.INTER_AREA)\n","# Add the image data to the list\n","data.append(resized)\n","# Add the label to the list\n","\n","# Convert the lists to numpy arrays\n","data = np.array(data)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr-kFllA4Bny"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtOAHVFU4DrG"},"outputs":[],"source":["# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPZCcqU74E_7"},"outputs":[],"source":["predicted_chaotic_image = autoencoder.predict(data[0].reshape(1,784))\n","print(predicted_chaotic_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BG45R-gl4GRI"},"outputs":[],"source":["# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(predicted_chaotic_image.reshape(28,28))\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BcqHt8M4Kvt"},"outputs":[],"source":["# # RECONSTRUCTION LOSS\n","# import tensorflow as tf\n","# print(tf.math.reduce_mean(predicted_chaotic_image.reshape(28,28)-tf.square(data[0].reshape(28,28))).numpy())\n","import tensorflow as tf\n","print(\"recon loss MSE\")\n","import numpy as np\n","\n","# assuming original_img and reconstructed_img are numpy arrays of shape (28, 28)\n","mse = np.mean((-data[0].reshape(28,28) + predicted_chaotic_image.reshape(28,28))**2)\n","print(mse)\n"]},{"cell_type":"markdown","metadata":{"id":"r5JX0syVD4pk"},"source":["# 4. Picking random image from test dataset and result reconstructed loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEexfHVMERQ1"},"outputs":[],"source":["import random\n","data = X_test[random.randint(1,len(X_test))].reshape(1,28,28)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FO9GABkgErSy"},"outputs":[],"source":["# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ahxn8o46ErSz"},"outputs":[],"source":["predicted_chaotic_image = autoencoder.predict(data[0].reshape(1,784))\n","print(predicted_chaotic_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-VvvKTwErSz"},"outputs":[],"source":["# Image from loaded array\n","import matplotlib.pyplot as plt\n","plt.imshow(predicted_chaotic_image.reshape(28,28))\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNpJhm65ErSz"},"outputs":[],"source":["# # RECONSTRUCTION LOSS\n","# import tensorflow as tf\n","# print(tf.math.reduce_mean(predicted_chaotic_image.reshape(28,28)-tf.square(data[0].reshape(28,28))).numpy())\n","import tensorflow as tf\n","print(\"recon loss MSE\")\n","import numpy as np\n","\n","# assuming original_img and reconstructed_img are numpy arrays of shape (28, 28)\n","mse = np.mean((-data[0].reshape(28,28) + predicted_chaotic_image.reshape(28,28))**2)\n","print(mse)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWHPevtGEssU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eNn1NMWOHdMO"},"source":["# 4. Picking 10 random images from test dataset and result reconstructed loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jE-cIQXhHfSb"},"outputs":[],"source":["import random\n","\n","images_10 = []\n","for i in range(10):\n","  data = X_test[random.randint(1,len(X_test))].reshape(1,28,28)\n","  # plt.imshow(data[0])\n","  images_10.append(data[0])\n","fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20, 4))\n","\n","# display each image in a separate subplot\n","\n","for i in range(10):\n","  axes[i].imshow(images_10[i].reshape(28,28))\n","  axes[i].axis('off')\n","# plt.title(\"Ground Truth Images\",fontsize=16, loc='center')\n","fig.suptitle('Ground Truth Images', fontsize=16, fontweight='bold')\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n2eg0fi9J8YT"},"outputs":[],"source":["predicted_images = []\n","for i in range(10):\n","  predicted_chaotic_image = autoencoder.predict(images_10[i].reshape(1,784))\n","  predicted_images.append(predicted_chaotic_image)\n","fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(20, 4))\n","\n","# display each image in a separate subplot\n","\n","for i in range(10):\n","  axes[i].imshow(predicted_images[i].reshape(28,28))\n","  axes[i].axis('off')\n","# plt.title(\"Ground Truth Images\",fontsize=16, loc='center')\n","fig.suptitle('Predicted Images', fontsize=16, fontweight='bold')\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3e08baRxLSJA"},"outputs":[],"source":["predicted_images = []\n","for i in range(10):\n","  predicted_chaotic_image = autoencoder.predict(images_10[i].reshape(1,784))\n","  predicted_images.append(predicted_chaotic_image)\n","fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(40, 8))\n","\n","# display each image in a separate subplot\n","for j in range(2):\n","  for i in range(10):\n","    if(j==1):\n","      axes[j][i].imshow(predicted_images[i].reshape(28,28))\n","      axes[j][i].axis('off')\n","      # axes[j].set_title('Predicted Images')\n","      axes[j][i].set_title('Predicted Image '+str(i))\n","      mse = np.mean((-images_10[i].reshape(28,28) + predicted_images[i].reshape(28,28))**2)\n","      # print(mse)\n","      string = \"Reconstruction Loss: \"+str(round(mse,8))\n","      axes[j][i].text(0.5, -0.1,string, fontsize=10, ha='center',transform=axes[j][i].transAxes)\n","    else:\n","      axes[j][i].imshow(images_10[i].reshape(28,28))\n","      axes[j][i].axis('off')\n","      axes[j][i].set_title('Ground Truth Image '+str(i))\n","      # axes[j].set_title('Ground Truth Images')\n","# plt.title(\"Ground Truth Images\",fontsize=16, loc='center')\n","fig.suptitle('Ground Truth Images 1st row, Predicted Images 2nd row', fontsize=16, fontweight='bold')\n","fig.tight_layout()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dmxhwPJJgh00"},"source":["#From the last meeting Stefano suggested to use:\n","\n","### ⛳Bottleneck = Shrink Size (have shrinked from 64 to 32)\n","\n","### ⛳Meaningful Dataset = As of now I am generating 'n' random gifs and saving their frames and putting them as dataset\n","\n","### ⛳ Stefano suggested to use deviation as measure of emerging pattern rather than reconstruction loss. \n","##### ==> so the idea is to maximise the deviation of reconstruction. The more the pixels are deviated over time in a reconstructed animation (so let say we have 100 frames of original rule set. those 100 frames vs same frames reconstructed through Autoencoder. The hypothesis is, if we have deviation in reconstruction of those 100 frames, that means there should be some non-boring behaviour)\n","\n","✅\n","Theory: Autoencoder is a type of neural network that can be used for dimensionality reduction and feature extraction. One way it can help in measuring complexity is by using reconstruction error.\n","\n","The basic idea of an autoencoder is to learn a compressed representation of the input data, and then use that representation to reconstruct the original data. The input data is first encoded into a compressed representation, which is then decoded back into the original data. The goal is to minimize the difference between the input data and the reconstructed output.\n","\n","If the autoencoder is successful in reconstructing the input data accurately, then the reconstruction error will be low. However, if the input data is complex and has a lot of variability, it may be difficult for the autoencoder to reconstruct the data accurately, resulting in a higher reconstruction error.\n","\n","Therefore, the reconstruction error can be used as a measure of complexity, where higher reconstruction error indicates higher complexity. This is because complex data is more difficult to accurately represent and reconstruct using a compressed representation.\n","\n","In summary, autoencoder can help in measuring complexity using reconstruction error, where the higher reconstruction error indicates higher complexity of the input data."]},{"cell_type":"markdown","metadata":{"id":"dB4jwYjwml0L"},"source":["### ⭐ How variation over time can be thought:\n","To use an autoencoder for time series data, you can treat each time step as a separate input and train the autoencoder to reconstruct the original sequence of data. The reconstruction loss, which is the difference between the input and the reconstructed output, can then be used to measure the complexity of the time series data.\n","\n","By analyzing the variation in the reconstruction loss over time, you can gain insights into the complexity of the time series. For example, if the reconstruction loss is relatively constant over time, it may indicate that the time series is relatively simple or predictable. However, if the reconstruction loss varies widely over time, it may indicate that the time series is more complex and difficult to predict.\n","\n","Additionally, you can use techniques such as spectral analysis or wavelet analysis to further analyze the variation in the reconstruction loss over time. These techniques can help identify patterns and correlations in the data that may not be immediately apparent from the reconstruction loss alone.\n","\n","In summary, using an autoencoder for time series data and analyzing the variation over time in the reconstruction loss can be a useful approach for measuring the complexity of the time series data."]},{"cell_type":"markdown","metadata":{"id":"KgakHt-BljWr"},"source":["# Let us analyse for one case:\n","### step1: generate one random pattern, save first 100 frames\n","### step2: generate reconstruction of those 100 frames using trained auto-encoder\n","### step3: check for variation in reconstruction loss over time between both the frame-sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFXWMbM9NPc7"},"outputs":[],"source":["lenia.run_simulation(\"outputs\") # saving one animation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1cy9d87KLqv"},"outputs":[],"source":["!mv /home/ec2-user/SageMaker/outputs/outputs/*/*.gif /home/ec2-user/SageMaker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NFjZcmNKirV"},"outputs":[],"source":["!rm -rf /home/ec2-user/SageMaker/outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOrEYJgUKn3q"},"outputs":[],"source":["!mkdir original100\n","!mv *.gif original100\n","%cd original100\n","!for file in *.gif; do ffmpeg -i \"$file\" \"${file%.*}-%d.jpg\"; done\n","%cd /home/ec2-user/SageMaker/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGFUT1n_LML6"},"outputs":[],"source":["%cd /home/ec2-user/SageMaker/original100\n","!i=1; for file in *; do mv \"$file\" \"$(printf '%d' $i).${file##*.}\"; ((i++)); done\n","%cd /home/ec2-user/SageMaker/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUagfumkLa6j"},"outputs":[],"source":["%cd /home/ec2-user/SageMaker/original100/\n","!rm *.gif\n","%cd /home/ec2-user/SageMaker/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YNg7EGwhLmNJ"},"outputs":[],"source":["!mkdir recon100\n","%cd recon100\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAMHC8jkNUwh"},"outputs":[],"source":["reconloss_list = []\n","\n","# Loop over the files in the folder and save predicted outputs as image in another folder recon100\n","for filename in os.listdir(\"/home/ec2-user/SageMaker/original100/\"):\n","    print(\"saving \",filename)\n","    data = []\n","    # Load the image using OpenCV\n","    img = cv2.imread(os.path.join(\"/home/ec2-user/SageMaker/original100/\", filename))\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Resize the image to a fixed size\n","    resized = cv2.resize(gray, (28, 28))\n","    # Add the image data to the list\n","    data.append(resized)\n","    # Add the label to the list\n","    data = np.array(data)\n","    predicted_data = autoencoder.predict(data.reshape(1,784))\n","    plt.imshow(predicted_data.reshape(28,28), cmap='gist_earth')\n","    plt.savefig(\"/home/ec2-user/SageMaker/recon100/\"+str(filename))\n","    mse = np.mean((-data.reshape(28,28) + predicted_data.reshape(28,28))**2)\n","    reconloss_list.append(mse)\n","    # plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o32nVGz8OyWW"},"outputs":[],"source":["print(\"The reconstruction loss between original data and the predicted or reconstructued data for 100 frames is:\")\n","print(reconloss_list)"]},{"cell_type":"markdown","metadata":{"id":"rCuyTkMXmE79"},"source":["# By analyzing the variation in the reconstruction loss over time, you can gain insights into the complexity of the time series. For example, if the reconstruction loss is relatively constant over time, it may indicate that the time series is relatively simple or predictable. However, if the reconstruction loss varies widely over time, it may indicate that the time series is more complex and difficult to predict."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKkfEgsQmTd3"},"outputs":[],"source":["import numpy as np\n","std_dev = np.std(reconloss_list)\n","\n","# Print the standard deviation of the list\n","print(\"Standard Deviation of the Reconstruction list is % s\" % (std_dev))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swATxpX9UvmR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fB4jUBvUvjZ"},"outputs":[],"source":["# def reconstruct_and_error(board):\n","#     data = []\n","#     # Load the image using OpenCV\n","#     img = np.array(board)\n","#     # Convert the image to grayscale\n","#     # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","#     # Resize the image to a fixed size\n","#     resized = cv2.resize(img, (28, 28))\n","#     # Add the image data to the list\n","#     data.append(resized)\n","#     # Add the label to the list\n","#     data = np.array(data)\n","#     predicted_data = autoencoder.predict(data.reshape(1,784), verbose=0)\n","#     plt.ioff()\n","#     # plt.imshow(predicted_data.reshape(28,28), cmap='gist_earth')\n","#     # plt.savefig(\"/content/recon100/\"+str(filename))\n","#     mse = np.mean((-data.reshape(28,28) + predicted_data.reshape(28,28))**2)\n","#     # reconloss_list.append(mse)\n","#     # std_dev = np.std(reconloss_list)\n","#     return mse\n","#     # plt.show()\n","\n","# # board = np.random.rand(100, 100)\n","# # # print(board.shape)\n","# # # print(board)\n","# # reco_loss = reconstruct_and_error(board)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ta2H6T71mtvK"},"outputs":[],"source":["\n","\n","# def calc_fitness(self, boards_list, gen):\n","#   errors = []\n","#   for i in range(len(boards_list)):\n","#     board_error = reconstruct_and_error(boards_list[i])\n","#     errors.append(board_error)\n","#   board_stddev = np.std(errors)\n","#   self.fitness = board_stddev\n","#   return self.fitness\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8EUNJUbbUsj"},"outputs":[],"source":["%cd /home/ec2-user/SageMaker/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Gdv8ScaclcO"},"outputs":[],"source":["\n","# Lenia for genetic Algorithm\n","\n","# Imports\n","# https://chakazul.github.io/Lenia/JavaScript/Lenia.html\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import time\n","import warnings\n","warnings.simplefilter(\"ignore\", UserWarning)\n","#Imports\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation\n","import scipy.signal\n","import os.path\n","import os\n","from datetime import datetime\n","from json import JSONEncoder\n","import json\n","from pathlib import Path\n","                \n","\n","OUTPUT_PATH = './outputs'\n","MAX_FRAMES = 3000\n","\n","mu = 0.31\n","sigma = 0.057\n","dt = 0.1\n","\n","\n","frames = 100\n","frame_intervals = float(50)\n","\n","\n","\n","class LeniaForGA:\n","    def __init__(self, kernel, board):\n","        self.sigma = sigma\n","        self.mu = mu\n","        self.dt = dt\n","        self.kernel = kernel\n","        self.normalise_kernel()\n","        self.frames = frames\n","        self.frame_intervals = frame_intervals\n","        self.anim = None\n","        self.lenia_board_state = {}\n","        # For random initialisation\n","        self.board = board\n","        self.cmap = 'viridis'\n","        self.fig, self.img = self.show_board()\n","        \n","\n","    # FLEXIBLITY TO CHANGE GROWTH FUNCTION\n","    def growth_function1(self, U:np.array):\n","        gaussian = lambda x, m, s: np.exp(-( (x-m)**2 / (2*s**2) ))\n","        return gaussian(U, self.mu, self.sigma)*2-1\n","\n","\n","    def show_board(self, \n","                   display:bool=False,\n","                   ):\n","        dpi = 50 # Using a higher dpi will result in higher quality graphics but will significantly affect computation\n","\n","        self.fig = plt.figure(figsize=(10*np.shape(self.board)[1]/dpi, 10*np.shape(self.board)[0]/dpi), dpi=dpi)\n","\n","        ax = self.fig.add_axes([0, 0, 1, 1])\n","        ax.axis('off')\n","        \n","        self.img = ax.imshow(self.board, cmap=self.cmap, interpolation='none', aspect=1, vmin=0) #  vmax=vmax\n","        \n","        if display:\n","            plt.show()\n","        else: # Do not show intermediate figures when creating animations (very slow)\n","            plt.close()\n","\n","        return self.fig, self.img\n","    \n","    \n","    def animate(self):\n","        self.anim =  matplotlib.animation.FuncAnimation(self.fig, self.animate_step, \n","                                            frames=self.frames, interval=self.frame_intervals, save_count=MAX_FRAMES, blit=True)\n","\n","    \n","    def animate_step(self, i:int) -> plt.imshow:\n","        neighbours = scipy.signal.convolve2d(self.board, self.kernel, mode='same', boundary='wrap')\n","        self.board = np.clip(self.board + self.dt * self.growth_function1(neighbours), 0, 1)\n","        # if (i+1) % 10 == 0:\n","        self.record_board_state(i)\n","        self.img.set_array(self.board) # render the updated state \n","        return self.img,\n","    \n","    \n","    def save_animation(self, dir, \n","                       filename:str,\n","                       ):\n","        if not self.anim:\n","            raise Exception('ERROR: Run animation before attempting to save')\n","            return \n","        output_path = OUTPUT_PATH+\"/\"+dir\n","        Path(output_path).mkdir(parents=True, exist_ok=True)\n","        fmt = os.path.splitext(filename)[1] # isolate the file extension\n","        \n","        if fmt == '.gif':\n","            f = os.path.join(output_path, filename) \n","            writer = matplotlib.animation.PillowWriter(fps=30) \n","            self.anim.save(f, writer=writer)\n","        else:\n","            raise Exception('ERROR: Unknown save format. Must be .gif or .mp4')\n","        # writer.close()\n","\n","    \n","    def normalise_kernel(self) -> np.array:\n","\n","        kernel_norm = self.kernel / (1*np.sum(self.kernel))\n","        self.norm_factor = 1/ (1*np.sum(self.kernel))\n","        self.kernel = kernel_norm \n","        return kernel_norm\n","        \n","        \n","    def plot_kernel_info(self,\n","                         dir,\n","                         cmap:str='viridis', \n","                         bar:bool=False,\n","                         save:str=None,\n","                         ) -> None:\n","\n","        \n","        k_xsection = self.kernel[self.kernel.shape[0] // 2, :]\n","        k_sum = np.sum(self.kernel)\n","        \n","        fig, ax = plt.subplots(1, 3, figsize=(14,2), gridspec_kw={'width_ratios': [1,1,2]})\n","        \n","        # Show kernel as heatmap\n","        ax[0].imshow(self.kernel, cmap=cmap, vmin=0)\n","        ax[0].title.set_text('Kernel')\n","        \n","        # Show kernel cross-section\n","        ax[1].title.set_text('Kernel Cross-section')\n","        if bar==True:\n","            ax[1].bar(range(0,len(k_xsection)), k_xsection, width=1)\n","        else:\n","            ax[1].plot(k_xsection)\n","        \n","        # Growth function\n","        ax[2].title.set_text('Growth Function')\n","        x = np.linspace(0, k_sum, 1000)\n","        ax[2].plot(x, self.growth_function1(x))\n","        \n","        if save:\n","            output_path = OUTPUT_PATH+\"/\"+dir\n","            Path(output_path).mkdir(parents=True, exist_ok=True)\n","            # print('Saving kernel and growth function info to', os.path.join(output_path, 'kernel_info'))\n","            \n","            plt.savefig(os.path.join(output_path, 'kernel_info.png') )\n","\n","\n","    def run_simulation(self, generation) -> None:\n","        self.animate()\n","        gif_dir = str(datetime.now())\n","        sub_dir = generation+\"/\"+gif_dir\n","        outfile = 'output.gif'   \n","        # print('./folder/{}...)'.format(sub_dir))\n","        \n","        self.save_animation(sub_dir, outfile)\n","        self.plot_kernel_info(dir=sub_dir, save=True)\n","        return self.lenia_board_state, sub_dir\n","\n","\n","    def record_board_state(self, i):\n","        # board_arr = self.board.flatten()\n","        # board_val_greater_than_point_five = list(board_arr[board_arr > 0.5])\n","        self.lenia_board_state[\"frame_\"+str(i+1)] = self.board\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3gUcwv7QNLF"},"outputs":[],"source":["\n","\n","# import random\n","# import numpy as np\n","# import shutil\n","# import os\n","# import statistics\n","# from matplotlib import pyplot as plt\n","# import sys\n","# import copy\n","# import multiprocessing\n","\n","\n","# kernel_size = 16\n","# board_size = 64\n","# mutation_rate = 0.1\n","# population_size = 10\n","# generation = 30\n","# gen_best_fitness = {}\n","# gen_average_fitness = {}\n","# each_gen_fitness = []\n","# no_of_elites = 1\n","\n","# def random_kernel_generator():\n","#   grid = np.random.rand(kernel_size, kernel_size)\n","#   grid = np.round(grid, 3)\n","#   return grid\n","\n","# def random_board_generator():\n","#   board = np.random.rand(board_size, board_size)\n","#   board = np.round(board, 3)\n","#   return board\n","\n","# class Individual(multiprocessing.Process):\n","\n","#   def __init__(self):\n","#     self.genes = random_kernel_generator()\n","#     self.fitness = 0\n","\n","#   def calc_fitness(self, board, gen):\n","#     lenia = Lenia(self.genes, board)\n","#     board_frames_dict = lenia.run_simulation(\"gen_\"+str(gen))\n","#     board_frames_val = list(board_frames_dict.values())\n","#     errors = []\n","#     for i in range(len(board_frames_val)):\n","#       board_error = reconstruct_and_error(board_frames_val[i])\n","#       errors.append(board_error)\n","#     board_stddev = np.std(errors)\n","#     self.fitness = board_stddev\n","#     return self.fitness\n","\n","\n","# class Population:\n","#   def __init__(self, size):\n","#     self.individuals = []\n","#     self.board = random_board_generator()\n","#     for _ in range(0, size):\n","#         self.individuals.append(Individual())\n","\n","\n","# class GeneticAlgorithm:\n","\n","#   #@staticmethod\n","#   def mutate_individuals(individuals):\n","#     mutated_individuals = []\n","#     for ind in individuals:\n","#         mutated_ind = GeneticAlgorithm._mutate_individual(ind)\n","#         mutated_individuals.append(mutated_ind)\n","#     return mutated_individuals\n","\n","#   #@staticmethod\n","#   def _mutate_individual(ind):\n","#     kernel = ind.genes\n","#     for i in range(kernel.shape[0]):\n","#         for j in range(kernel.shape[1]):\n","#             if random.random() < mutation_rate:\n","#                 kernel[i][j] = np.round(np.random.rand(), 3)\n","#     ind.genes = kernel\n","#     return ind\n","    \n","#   #@staticmethod\n","#   def select_roulette_wheel(individuals):\n","#     original_individuals = individuals\n","#     individual_length = len(original_individuals)\n","#     new_individuals = []\n","#     total_sum = 0\n","#     total_sum = sum([(total_sum + ind.fitness) for ind in individuals])\n","#     print(\"total sum: \", total_sum)\n","#     # random_num = random.randrange(0,int(round(total_sum)))\n","#     random_num = random.uniform(0,total_sum)\n","#     partial_sum = 0\n","#     while len(new_individuals) != individual_length - no_of_elites:\n","#         for c in original_individuals:\n","#             partial_sum += c.fitness\n","#             if(partial_sum >= random_num):\n","#                 new_individuals.append(c)\n","#                 # random_num = random.randrange(0,int(round(total_sum)))\n","#                 random_num = random.uniform(0,total_sum)\n","#                 partial_sum = 0\n","#                 break\n","#     print(\"Roulette - Selected Individuals Fitness: \",  [ind.fitness for ind in new_individuals])\n","#     return new_individuals\n","\n","# def run_ga(pop_size, generation):\n","#   population = Population(pop_size)\n","#   board = population.board\n","#   population.individuals.sort(key=lambda x: x.calc_fitness(board=board, gen=1), reverse= True)\n","#   for gen in range(1, generation+1):\n","#       print(\"Generation: \", gen, \" started\")\n","#       gen_fitness_dict = {}\n","#       gen_best_fitness[\"gen_\"+str(gen)] = population.individuals[0].fitness\n","#       all_fitness = [ind.fitness for ind in population.individuals]\n","#       gen_fitness_dict[\"gen_\"+str(gen)] = all_fitness\n","#       print(\"Fitness of this generation: \", all_fitness)\n","#       each_gen_fitness.append(gen_fitness_dict)\n","#       gen_average_fitness[\"gen_\"+str(gen)] = sum(all_fitness)/len(all_fitness)\n","#       elite_individuals = [copy.deepcopy(population.individuals[i]) for i in range(0,no_of_elites)]\n","#       selected_individuals = GeneticAlgorithm.select_roulette_wheel(population.individuals)\n","#       mutated_individuals = GeneticAlgorithm.mutate_individuals(selected_individuals)\n","#       for ind in mutated_individuals:\n","#         ind.calc_fitness(board, gen)\n","#       print(\"Mutated population fitness: \",  [ind.fitness for ind in mutated_individuals])\n","#       population.individuals = elite_individuals + mutated_individuals    \n","#       population.individuals.sort(key=lambda x: x.fitness, reverse= True)\n","#       print(\"elite fitness: \", [ind.fitness for ind in elite_individuals])\n","#       print(\"Next generation fitness : \", [ind.fitness for ind in population.individuals])\n","#       print(\"Generation \",gen, \" completed\")\n","#       print(\"----------------------------------\")\n","#       print(\"----------------------------------\")\n","\n","#   print(\"gen_best_fitness: \", gen_best_fitness)\n","#   plot_figures(gen_best_fitness, \"gen_best_fitness.png\")\n","#   print(\"gen_average_fitness: \", gen_average_fitness)\n","#   plot_figures(gen_average_fitness, \"gen_average_fitness.png\")\n","\n","\n","# def plot_figures(data, name):\n","#   plt.clf()\n","#   labels = list(data.keys())\n","#   values = list(data.values())\n","#   plt.plot(labels, values)\n","#   plt.xlabel('Generation')\n","#   plt.ylabel('Fitness')\n","#   plt.title('Fitness of Generations')\n","#   plt.savefig(name) \n","\n","# if __name__ == \"__main__\":\n","    \n","#   if os.path.exists('outputs'):\n","#     shutil.rmtree('outputs')\n","#   run_ga(population_size, generation)"]},{"cell_type":"markdown","metadata":{"id":"8nP-qHhM98f9"},"source":["# Merged VoT and AE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1O4AiUF9pJv"},"outputs":[],"source":["\n","def reconstruct_and_error(board):\n","    data = []\n","    # Load the image using OpenCV\n","    img = np.array(board)\n","    # Convert the image to grayscale\n","    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Resize the image to a fixed size\n","    resized = cv2.resize(img, (28, 28))\n","    # Add the image data to the list\n","    data.append(resized)\n","    # Add the label to the list\n","    data = np.array(data)\n","    predicted_data = autoencoder.predict(data.reshape(1,784), verbose=0)\n","    plt.ioff()\n","    # plt.imshow(predicted_data.reshape(28,28), cmap='gist_earth')\n","    # plt.savefig(\"/content/recon100/\"+str(filename))\n","    mse = np.mean((-data.reshape(28,28) + predicted_data.reshape(28,28))**2)\n","    # reconloss_list.append(mse)\n","    # std_dev = np.std(reconloss_list)\n","    return predicted_data.reshape(28,28), mse\n","    # plt.show()\n","\n","# board = np.random.rand(100, 100)\n","# # print(board.shape)\n","# # print(board)\n","# reco_loss = reconstruct_and_error(board)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mdm5UfupqbxV"},"outputs":[],"source":["# Updated with merged lenia-ae and vot\n","\n","import random\n","import numpy as np\n","import shutil\n","import os\n","import statistics\n","from matplotlib import pyplot as plt\n","import sys\n","import copy\n","import multiprocessing\n","import pandas as pd\n","\n","\n","elite_filename = {}\n","\n","kernel_size = 16\n","board_size = 64\n","mutation_rate = 0.02\n","population_size = 10\n","generation = 500\n","gen_best_fitness = {}\n","gen_average_fitness = {}\n","each_gen_fitness = []\n","no_of_elites = 1\n","\n","\n","OUTPUT_PATH = './outputs'\n","\n","def random_kernel_generator():\n","  grid = np.random.rand(kernel_size, kernel_size)\n","  grid = np.round(grid, 3)\n","  return grid\n","\n","def random_board_generator():\n","  board = np.random.rand(board_size, board_size)\n","  board = np.round(board, 3)\n","  return board\n","\n","class Individual(multiprocessing.Process):\n","\n","  def __init__(self):\n","    self.genes = random_kernel_generator()\n","    self.fitness = 0\n","    self.saved_dir = None\n","\n","  def calc_fitness(self, board, gen):\n","    lenia = LeniaForGA(self.genes, board)\n","    board_frames_dict, dir = lenia.run_simulation(\"gen_\"+str(gen))\n","    self.saved_dir = dir\n","    board_frames_val = list(board_frames_dict.values())\n","    errors = []\n","    frame_alive_cell_count_list = []\n","    for i in range(len(board_frames_val)):\n","      frame, board_error = reconstruct_and_error(board_frames_val[i])\n","      errors.append(board_error)\n","      board_arr = frame.flatten()\n","      alive_cell_count = list(board_arr[board_arr > 0.3])\n","      frame_alive_cell_count_list.append(len(alive_cell_count))\n","\n","    frame_info = frame_alive_cell_count_list\n","    self.fitness = statistics.pstdev(frame_info)\n","    # board_stddev = np.std(errors)\n","    # self.fitness = board_stddev\n","    \n","    return self.fitness\n","\n","\n","class Population:\n","  def __init__(self, size):\n","    self.individuals = []\n","    self.board = random_board_generator()\n","    for _ in range(0, size):\n","        self.individuals.append(Individual())\n","\n","\n","class GeneticAlgorithm:\n","\n","  @staticmethod\n","  def mutate_individuals(individuals):\n","    mutated_individuals = []\n","    for ind in individuals:\n","        mutated_ind = GeneticAlgorithm._mutate_individual(ind)\n","        mutated_individuals.append(mutated_ind)\n","    return mutated_individuals\n","\n","  @staticmethod\n","  def _mutate_individual(ind):\n","    kernel = ind.genes\n","    for i in range(kernel.shape[0]):\n","        for j in range(kernel.shape[1]):\n","            if random.random() < mutation_rate:\n","                kernel[i][j] = np.round(np.random.rand(), 3)\n","    ind.genes = kernel\n","    return ind\n","    \n","  @staticmethod\n","  def select_roulette_wheel(individuals):\n","    original_individuals = individuals\n","    individual_length = len(original_individuals)\n","    new_individuals = []\n","    total_sum = 0\n","    total_sum = sum([(total_sum + ind.fitness) for ind in individuals])\n","    print(\"total sum: \", total_sum)\n","    # random_num = random.randrange(0,int(round(total_sum)))\n","    random_num = random.uniform(0,total_sum)\n","    partial_sum = 0\n","    while len(new_individuals) != individual_length - no_of_elites:\n","        for c in original_individuals:\n","            partial_sum += c.fitness\n","            if(partial_sum >= random_num):\n","                new_individuals.append(c)\n","                # random_num = random.randrange(0,int(round(total_sum)))\n","                random_num = random.uniform(0,total_sum)\n","                partial_sum = 0\n","                break\n","    print(\"Roulette - Selected Individuals Fitness: \",  [ind.fitness for ind in new_individuals])\n","    return new_individuals\n","\n","def move_elite(dir):\n","  main_elite_dir = \"elite_dir\"\n","  if not os.path.isdir(main_elite_dir):\n","    os.makedirs(main_elite_dir)\n","  \n","  main_dir, sub_dir = os.path.split(dir)\n","  shutil.move(OUTPUT_PATH +\"/\"+ dir, main_elite_dir+'/'+main_dir)\n","  \n","\n","def run_ga(pop_size, generation):\n","  population = Population(pop_size)\n","  board = population.board\n","  population.individuals.sort(key=lambda x: x.calc_fitness(board=board, gen=1), reverse= True)\n","  df = pd.DataFrame(columns=[\n","                      'gen', 'gen_best_fitness', 'gen_average_fitness'], index=[0])\n","  for gen in range(1, generation+1):\n","      print(\"Generation: \", gen, \" started\")\n","      df.loc[gen - 1, 'gen'] = gen\n","      gen_fitness_dict = {}\n","      gen_best_fitness[\"gen_\"+str(gen)] = population.individuals[0].fitness\n","      print(\"Best gen dir: \", population.individuals[0].gif_dir)\n","      if os.path.isdir(OUTPUT_PATH +\"/\"+ population.individuals[0].gif_dir):\n","        move_elite(population.individuals[0].gif_dir)\n","      shutil.rmtree(OUTPUT_PATH +\"/\"+ \"gen_\"+str(gen))\n","      df.loc[gen - 1, 'gen_best_fitness'] = population.individuals[0].fitness\n","      gif_dir = population.individuals[0].gif_dir\n","      all_fitness = [ind.fitness for ind in population.individuals]\n","      gen_fitness_dict[\"gen_\"+str(gen)] = all_fitness\n","      print(\"Fitness of this generation: \", all_fitness)\n","      each_gen_fitness.append(gen_fitness_dict)\n","      gen_average_fitness[\"gen_\"+str(gen)] = sum(all_fitness)/len(all_fitness)\n","      df.loc[gen - 1, 'gen_average_fitness'] = sum(all_fitness)/len(all_fitness)\n","      elite_individuals = [copy.deepcopy(population.individuals[i]) for i in range(0,no_of_elites)]\n","      selected_individuals = GeneticAlgorithm.select_roulette_wheel(population.individuals)\n","      mutated_individuals = GeneticAlgorithm.mutate_individuals(selected_individuals)\n","      for ind in mutated_individuals:\n","        ind.calc_fitness(board, gen + 1)\n","      # print(\"Mutated population fitness: \",  [ind.fitness for ind in mutated_individuals])\n","      population.individuals = elite_individuals + mutated_individuals    \n","      population.individuals.sort(key=lambda x: x.fitness, reverse= True)\n","      print(\"elite fitness: \", [ind.fitness for ind in elite_individuals])\n","      # print(\"Next generation fitness : \", [ind.fitness for ind in population.individuals])\n","      print(\"Generation \",gen, \" completed\")\n","      print(\"----------------------------------\")\n","      print(\"----------------------------------\") \n","\n","  df.to_csv('AE_VOT|P10|G500|M0.02|ALIVE_CELL_THRESHOLD0.3|100_FRAMES.csv', index=False)\n","\n","\n","def plot_figures(data, name):\n","  plt.clf()\n","  labels = list(data.keys())\n","  values = list(data.values())\n","  plt.plot(labels, values)\n","  plt.xlabel('Generation')\n","  plt.ylabel('Fitness')\n","  plt.title('Fitness of Generations')\n","  plt.savefig(name) \n","\n","if __name__ == \"__main__\":\n","    \n","  if os.path.exists('outputs'):\n","    shutil.rmtree('outputs')\n","  run_ga(population_size, generation)\n","  print(\"Elite gif directory\")\n","  print(elite_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Uv2ayZutoQD"},"outputs":[],"source":["\n","current_dir = !pwd\n","output_dirs = current_dir[0]+'/outputs'\n","elite_folder = output_dirs+'/elites'\n","if not os.path.exists(elite_folder):\n","    os.makedirs(elite_folder)\n","print(output_dirs)\n","for key, val in elite_filename.items():\n","  output_gif = output_dirs+\"/\"+val+\"/output.gif\"\n","  kernel = output_dirs+\"/\"+val+\"/kernel_info.png\"\n","  shutil.copy(output_gif, elite_folder)\n","  shutil.copy(kernel, elite_folder)\n","\n","  # Rename the copied file to the new name\n","  new_path = os.path.join(elite_folder, key+\"_output.gif\")\n","  os.rename(os.path.join(elite_folder, os.path.basename(output_gif)), new_path)\n","\n","  new_path = os.path.join(elite_folder, key+\"_kernel.png\")\n","  os.rename(os.path.join(elite_folder, os.path.basename(kernel)), new_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hqXrK49W4q_"},"outputs":[],"source":["!zip -r elites_exp12.zip /home/ec2-user/SageMaker/outputs/elites/"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"conda_python3","language":"python","name":"conda_python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}