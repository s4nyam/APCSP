{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVaoUuG8w-T",
        "outputId": "f5c44de4-a1b8-4b78-ad35-4e5ecf9d48a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_dataset_chaotic | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzMOr2sCFgiQ",
        "outputId": "1280d65c-846c-4dc9-d84b-791f8f45f9d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import random\n",
        "\n",
        "# def delete_random_files(folder_path, num_files):\n",
        "#     # Get a list of all the files in the folder\n",
        "#     files = os.listdir(folder_path)\n",
        "#     # Shuffle the list of files randomly\n",
        "#     random.shuffle(files)\n",
        "#     # Loop over the shuffled list and delete the first num_files files\n",
        "#     for filename in files[:num_files]:\n",
        "#         # Get the full path of the file\n",
        "#         file_path = os.path.join(folder_path, filename)\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         # print(f\"Deleted file: {file_path}\")\n",
        "\n",
        "# # Example usage\n",
        "# folder_path = \"/content/drive/MyDrive/lenia_dataset\"\n",
        "# num_files_to_delete = 6950\n",
        "# delete_random_files(folder_path, num_files_to_delete)\n"
      ],
      "metadata": {
        "id": "wKcYc9yuUp6m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_dataset_chaotic | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amFIjYiRU91m",
        "outputId": "a845bd41-8cf5-475c-c939-34e3935a1537"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the path to the folder containing the images\n",
        "folder_path = \"/content/drive/MyDrive/lenia_dataset_chaotic/\"\n",
        "\n",
        "# Initialize lists to hold the image data and labels\n",
        "data = []\n",
        "\n",
        "# Loop over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(os.path.join(folder_path, filename))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image to a fixed size\n",
        "    resized = cv2.resize(gray, (28, 28))\n",
        "    # Add the image data to the list\n",
        "    data.append(resized)\n",
        "    # Add the label to the list\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "data = np.array(data)\n",
        "\n",
        "# Split the data into training and testing sets\n"
      ],
      "metadata": {
        "id": "PVrlDRbAR1DM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest = train_test_split(data, test_size=0.3, random_state=2)\n"
      ],
      "metadata": {
        "id": "hxKS-k9PachM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = xtrain.reshape(xtrain.shape[0], 28, 28, 1)\n",
        "X_test = xtest.reshape(xtest.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "hVnVmgFoak-7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.layers import Layer\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, add\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "o4HDmElbT3vW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(\"float32\")/255.\n",
        "X_test = X_test.astype(\"float32\")/255.\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_NV0yoUYFJ",
        "outputId": "ee0c274f-55eb-400e-8b7b-ef62594c8c29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (49, 28, 28, 1)\n",
            "49 train samples\n",
            "22 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
      ],
      "metadata": {
        "id": "AIAPAmWQeiCn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 64\n",
        "output_size = 784"
      ],
      "metadata": {
        "id": "bUUrrS5BemKx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h = Dense(hidden_size, activation='relu')(x)\n",
        "r = Dense(output_size, activation='sigmoid')(h)\n",
        "\n",
        "autoencoder = Model(inputs=x, outputs=r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "NZ1kOsbaerAl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "Elx0KmSuesZL",
        "outputId": "de2842cc-87fb-4e72-e0a2-6aa3240ead70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"191pt\" height=\"255pt\" viewBox=\"0.00 0.00 143.00 191.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-187 139,-187 139,4 -4,4\"/>\n<!-- 139629293038176 -->\n<g id=\"node1\" class=\"node\">\n<title>139629293038176</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-146.5 0,-182.5 135,-182.5 135,-146.5 0,-146.5\"/>\n<text text-anchor=\"middle\" x=\"29\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">input_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"58,-146.5 58,-182.5 \"/>\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n</g>\n<!-- 139629293038128 -->\n<g id=\"node2\" class=\"node\">\n<title>139629293038128</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"19,-73.5 19,-109.5 116,-109.5 116,-73.5 19,-73.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"66,-73.5 66,-109.5 \"/>\n<text text-anchor=\"middle\" x=\"91\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 139629293038176&#45;&gt;139629293038128 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139629293038176-&gt;139629293038128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-146.31C67.5,-138.29 67.5,-128.55 67.5,-119.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-119.53 67.5,-109.53 64,-119.53 71,-119.53\"/>\n</g>\n<!-- 139629292722928 -->\n<g id=\"node3\" class=\"node\">\n<title>139629292722928</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-0.5 12,-36.5 123,-36.5 123,-0.5 12,-0.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"73,-0.5 73,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"98\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 139629293038128&#45;&gt;139629292722928 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139629293038128-&gt;139629292722928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-73.31C67.5,-65.29 67.5,-55.55 67.5,-46.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-46.53 67.5,-36.53 64,-46.53 71,-46.53\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 128\n",
        "\n",
        "history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bXE6xFXet1a",
        "outputId": "054d08cd-4982-4fdb-b4e9-c57b88abd013"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0543 - val_loss: 0.0541\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0517 - val_loss: 0.0522\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0498 - val_loss: 0.0503\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0480 - val_loss: 0.0482\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0459 - val_loss: 0.0458\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0435 - val_loss: 0.0432\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0410 - val_loss: 0.0405\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0382 - val_loss: 0.0377\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0355 - val_loss: 0.0348\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0327 - val_loss: 0.0321\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0300 - val_loss: 0.0294\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0274 - val_loss: 0.0270\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0250 - val_loss: 0.0248\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0228 - val_loss: 0.0228\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0209 - val_loss: 0.0210\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0192 - val_loss: 0.0195\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0176 - val_loss: 0.0182\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0163 - val_loss: 0.0170\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0151 - val_loss: 0.0160\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0141 - val_loss: 0.0152\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0125 - val_loss: 0.0139\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0114 - val_loss: 0.0130\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0110 - val_loss: 0.0127\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0107 - val_loss: 0.0125\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0104 - val_loss: 0.0123\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0102 - val_loss: 0.0122\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0100 - val_loss: 0.0121\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0099 - val_loss: 0.0120\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0098 - val_loss: 0.0119\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0097 - val_loss: 0.0118\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0096 - val_loss: 0.0117\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0095 - val_loss: 0.0116\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0094 - val_loss: 0.0115\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0093 - val_loss: 0.0114\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0092 - val_loss: 0.0113\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0091 - val_loss: 0.0113\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0090 - val_loss: 0.0112\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0089 - val_loss: 0.0111\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0089 - val_loss: 0.0111\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0088 - val_loss: 0.0110\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0087 - val_loss: 0.0109\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0087 - val_loss: 0.0109\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0086 - val_loss: 0.0108\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0085 - val_loss: 0.0107\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0085 - val_loss: 0.0107\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0084 - val_loss: 0.0106\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0083 - val_loss: 0.0105\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0083 - val_loss: 0.0105\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0082 - val_loss: 0.0104\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0082 - val_loss: 0.0103\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.0103\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0080 - val_loss: 0.0102\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0080 - val_loss: 0.0101\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0079 - val_loss: 0.0100\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0078 - val_loss: 0.0100\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0077 - val_loss: 0.0099\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.0098\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0076 - val_loss: 0.0097\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0075 - val_loss: 0.0097\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0074 - val_loss: 0.0096\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0074 - val_loss: 0.0095\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0072 - val_loss: 0.0093\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0071 - val_loss: 0.0093\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0070 - val_loss: 0.0092\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0069 - val_loss: 0.0091\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0069 - val_loss: 0.0090\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0068 - val_loss: 0.0089\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0067 - val_loss: 0.0089\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0066 - val_loss: 0.0088\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0065 - val_loss: 0.0087\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0064 - val_loss: 0.0086\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0063 - val_loss: 0.0086\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0063 - val_loss: 0.0085\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0062 - val_loss: 0.0084\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.0083\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0060 - val_loss: 0.0083\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.0082\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - val_loss: 0.0081\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0058 - val_loss: 0.0081\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0057 - val_loss: 0.0080\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0056 - val_loss: 0.0079\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0056 - val_loss: 0.0079\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0055 - val_loss: 0.0078\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0054 - val_loss: 0.0078\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0053 - val_loss: 0.0077\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0053 - val_loss: 0.0076\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0052 - val_loss: 0.0076\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0051 - val_loss: 0.0075\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0075\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.0075\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.0074\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0049 - val_loss: 0.0074\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0048 - val_loss: 0.0073\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0048 - val_loss: 0.0073\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.0072\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0047 - val_loss: 0.0072\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0046 - val_loss: 0.0072\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.0071\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0045 - val_loss: 0.0071\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.0071\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0044 - val_loss: 0.0070\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0044 - val_loss: 0.0070\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.0070\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0070\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0069\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0042 - val_loss: 0.0069\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0069\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.0068\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0041 - val_loss: 0.0068\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0041 - val_loss: 0.0068\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0040 - val_loss: 0.0068\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0040 - val_loss: 0.0068\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0040 - val_loss: 0.0067\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0039 - val_loss: 0.0067\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0039 - val_loss: 0.0067\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0067\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0037 - val_loss: 0.0065\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0033 - val_loss: 0.0062\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.0061\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.0060\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0029 - val_loss: 0.0059\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0028 - val_loss: 0.0058\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.0058\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - val_loss: 0.0058\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - val_loss: 0.0058\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - val_loss: 0.0058\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0028 - val_loss: 0.0057\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.0057\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - val_loss: 0.0057\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - val_loss: 0.0057\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0027 - val_loss: 0.0057\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0027 - val_loss: 0.0056\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - val_loss: 0.0056\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - val_loss: 0.0056\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0056\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - val_loss: 0.0056\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0026 - val_loss: 0.0056\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - val_loss: 0.0055\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.0055\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.0026 - val_loss: 0.0055\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0055\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 0.0052\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0024 - val_loss: 0.0052\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 0.0052\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0024 - val_loss: 0.0052\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - val_loss: 0.0051\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0023 - val_loss: 0.0050\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0023 - val_loss: 0.0050\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0023 - val_loss: 0.0050\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 0.0050\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0022 - val_loss: 0.0049\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.0048\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.0048\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.0047\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0021 - val_loss: 0.0046\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.0046\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.0045\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0020 - val_loss: 0.0044\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.0044\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - val_loss: 0.0044\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0019 - val_loss: 0.0044\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.0043\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.0042\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.0042\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.0041\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.0040\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0040\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0017 - val_loss: 0.0040\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0040\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0039\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0017 - val_loss: 0.0038\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0038\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0036\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.0036\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.0035\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - val_loss: 0.0034\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.0033\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0014 - val_loss: 0.0032\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0014 - val_loss: 0.0032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder = Model(x, h)\n",
        "encoded_imgs = conv_encoder.predict(X_test)\n",
        "\n",
        "n = 1\n",
        "plt.figure(figsize=(28, 10))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 16).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "QLmpqHMBevu5",
        "outputId": "09ccaeb1-cc4a-4c67-f97f-077f9c33cb15"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExA7kO63eyvD",
        "outputId": "6d016625-f078-4c7a-cfc9-9d99a55c23ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "plt.figure(figsize=(28, 28))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28),cmap=\"gist_earth\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "SSiPSKeNfgce",
        "outputId": "4e07e5a0-041b-46b5-eb27-57990c175588"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(28,28))\n",
        "for i in range(n):    \n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i+n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap=\"gist_earth\")\n",
        "    # plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tOLD93oKgHb3",
        "outputId": "8ee482ad-da51-4256-bff8-b55b43bde33d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "pJ9a9Kp2fiPO",
        "outputId": "9ae8d5a6-5e8f-4951-8f02-d7f14ba8cc3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "for i in range(n):\n",
        "  print(\"Error or loss for the image \"+str(i))\n",
        "  print(tf.math.reduce_mean(tf.square(decoded_imgs[i].reshape(28, 28)-X_test[i].reshape(28, 28))))\n",
        "  print(\"------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65L7IaM-foed",
        "outputId": "e3dcdef3-5efe-4a13-d316-4285f8c16f8f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error or loss for the image 0\n",
            "tf.Tensor(0.008771655, shape=(), dtype=float32)\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wbaHstUEr_AA"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}