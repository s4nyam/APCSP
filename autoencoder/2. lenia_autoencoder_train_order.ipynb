{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeVaoUuG8w-T",
        "outputId": "85695490-5832-4997-b440-6887bbeab57d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_dataset_order | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzMOr2sCFgiQ",
        "outputId": "cb5c28b6-4060-4be0-b28a-5b89b83bc5a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import random\n",
        "\n",
        "# def delete_random_files(folder_path, num_files):\n",
        "#     # Get a list of all the files in the folder\n",
        "#     files = os.listdir(folder_path)\n",
        "#     # Shuffle the list of files randomly\n",
        "#     random.shuffle(files)\n",
        "#     # Loop over the shuffled list and delete the first num_files files\n",
        "#     for filename in files[:num_files]:\n",
        "#         # Get the full path of the file\n",
        "#         file_path = os.path.join(folder_path, filename)\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         # print(f\"Deleted file: {file_path}\")\n",
        "\n",
        "# # Example usage\n",
        "# folder_path = \"/content/drive/MyDrive/lenia_dataset\"\n",
        "# num_files_to_delete = 6950\n",
        "# delete_random_files(folder_path, num_files_to_delete)\n"
      ],
      "metadata": {
        "id": "wKcYc9yuUp6m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/lenia_dataset_order | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amFIjYiRU91m",
        "outputId": "17ec297f-4a7f-4d1b-9c3f-12a9d9a0870c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the path to the folder containing the images\n",
        "folder_path = \"/content/drive/MyDrive/lenia_dataset_order/\"\n",
        "\n",
        "# Initialize lists to hold the image data and labels\n",
        "data = []\n",
        "\n",
        "# Loop over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(os.path.join(folder_path, filename))\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image to a fixed size\n",
        "    resized = cv2.resize(gray, (28, 28))\n",
        "    # Add the image data to the list\n",
        "    data.append(resized)\n",
        "    # Add the label to the list\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "data = np.array(data)\n",
        "\n",
        "# Split the data into training and testing sets\n"
      ],
      "metadata": {
        "id": "PVrlDRbAR1DM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xtest = train_test_split(data, test_size=0.3, random_state=2)\n"
      ],
      "metadata": {
        "id": "hxKS-k9PachM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = xtrain.reshape(xtrain.shape[0], 28, 28, 1)\n",
        "X_test = xtest.reshape(xtest.shape[0], 28, 28, 1)"
      ],
      "metadata": {
        "id": "hVnVmgFoak-7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.layers import Layer\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, add\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "o4HDmElbT3vW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(\"float32\")/255.\n",
        "X_test = X_test.astype(\"float32\")/255.\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_NV0yoUYFJ",
        "outputId": "963728ca-a083-4179-e1e6-c6e9017ee19e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (226, 28, 28, 1)\n",
            "226 train samples\n",
            "98 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))"
      ],
      "metadata": {
        "id": "AIAPAmWQeiCn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 64\n",
        "output_size = 784"
      ],
      "metadata": {
        "id": "bUUrrS5BemKx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape=(input_size,))\n",
        "h = Dense(hidden_size, activation='relu')(x)\n",
        "r = Dense(output_size, activation='sigmoid')(h)\n",
        "\n",
        "autoencoder = Model(inputs=x, outputs=r)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "NZ1kOsbaerAl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "Elx0KmSuesZL",
        "outputId": "1addd59c-7ca2-48d1-b65a-dc26e34e2aab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"191pt\" height=\"255pt\" viewBox=\"0.00 0.00 143.00 191.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-187 139,-187 139,4 -4,4\"/>\n<!-- 140323639750176 -->\n<g id=\"node1\" class=\"node\">\n<title>140323639750176</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-146.5 0,-182.5 135,-182.5 135,-146.5 0,-146.5\"/>\n<text text-anchor=\"middle\" x=\"29\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">input_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"58,-146.5 58,-182.5 \"/>\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-160.8\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n</g>\n<!-- 140323639750272 -->\n<g id=\"node2\" class=\"node\">\n<title>140323639750272</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"19,-73.5 19,-109.5 116,-109.5 116,-73.5 19,-73.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"66,-73.5 66,-109.5 \"/>\n<text text-anchor=\"middle\" x=\"91\" y=\"-87.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 140323639750176&#45;&gt;140323639750272 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140323639750176-&gt;140323639750272</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-146.31C67.5,-138.29 67.5,-128.55 67.5,-119.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-119.53 67.5,-109.53 64,-119.53 71,-119.53\"/>\n</g>\n<!-- 140323639234512 -->\n<g id=\"node3\" class=\"node\">\n<title>140323639234512</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"12,-0.5 12,-36.5 123,-36.5 123,-0.5 12,-0.5\"/>\n<text text-anchor=\"middle\" x=\"42.5\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">dense_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"73,-0.5 73,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"98\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n</g>\n<!-- 140323639750272&#45;&gt;140323639234512 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140323639750272-&gt;140323639234512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.5,-73.31C67.5,-65.29 67.5,-55.55 67.5,-46.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"71,-46.53 67.5,-36.53 64,-46.53 71,-46.53\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "batch_size = 128\n",
        "\n",
        "history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bXE6xFXet1a",
        "outputId": "e6e4b76f-8070-4adf-f93d-4b2a08669f3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "2/2 [==============================] - 1s 179ms/step - loss: 0.1187 - val_loss: 0.1147\n",
            "Epoch 2/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1139 - val_loss: 0.1107\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1096 - val_loss: 0.1053\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1037 - val_loss: 0.0984\n",
            "Epoch 5/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0966 - val_loss: 0.0910\n",
            "Epoch 6/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0890 - val_loss: 0.0839\n",
            "Epoch 7/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0820 - val_loss: 0.0774\n",
            "Epoch 8/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0756 - val_loss: 0.0715\n",
            "Epoch 9/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0698 - val_loss: 0.0660\n",
            "Epoch 10/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0645 - val_loss: 0.0610\n",
            "Epoch 11/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0597 - val_loss: 0.0565\n",
            "Epoch 12/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0555 - val_loss: 0.0524\n",
            "Epoch 13/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0516 - val_loss: 0.0488\n",
            "Epoch 14/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0481 - val_loss: 0.0454\n",
            "Epoch 15/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0448 - val_loss: 0.0422\n",
            "Epoch 16/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0417 - val_loss: 0.0392\n",
            "Epoch 17/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0387 - val_loss: 0.0364\n",
            "Epoch 18/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0360 - val_loss: 0.0339\n",
            "Epoch 19/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0335 - val_loss: 0.0315\n",
            "Epoch 20/300\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0312 - val_loss: 0.0294\n",
            "Epoch 21/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0291 - val_loss: 0.0276\n",
            "Epoch 22/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0272 - val_loss: 0.0259\n",
            "Epoch 23/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0254 - val_loss: 0.0244\n",
            "Epoch 24/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0238 - val_loss: 0.0230\n",
            "Epoch 25/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0224 - val_loss: 0.0218\n",
            "Epoch 26/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0212 - val_loss: 0.0207\n",
            "Epoch 27/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0200 - val_loss: 0.0197\n",
            "Epoch 28/300\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0190 - val_loss: 0.0188\n",
            "Epoch 29/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0181 - val_loss: 0.0180\n",
            "Epoch 30/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0173 - val_loss: 0.0173\n",
            "Epoch 31/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0166 - val_loss: 0.0166\n",
            "Epoch 32/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0159 - val_loss: 0.0160\n",
            "Epoch 33/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0153 - val_loss: 0.0154\n",
            "Epoch 34/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0149\n",
            "Epoch 35/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0144\n",
            "Epoch 36/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0137 - val_loss: 0.0140\n",
            "Epoch 37/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0133 - val_loss: 0.0135\n",
            "Epoch 38/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0128 - val_loss: 0.0131\n",
            "Epoch 39/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0124 - val_loss: 0.0127\n",
            "Epoch 40/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0120 - val_loss: 0.0123\n",
            "Epoch 41/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0117 - val_loss: 0.0119\n",
            "Epoch 42/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0113 - val_loss: 0.0116\n",
            "Epoch 43/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0110 - val_loss: 0.0112\n",
            "Epoch 44/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0107 - val_loss: 0.0109\n",
            "Epoch 45/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0103 - val_loss: 0.0106\n",
            "Epoch 46/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0100 - val_loss: 0.0103\n",
            "Epoch 47/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0098 - val_loss: 0.0100\n",
            "Epoch 48/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0095 - val_loss: 0.0098\n",
            "Epoch 49/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0093 - val_loss: 0.0095\n",
            "Epoch 50/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0090 - val_loss: 0.0093\n",
            "Epoch 51/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0088 - val_loss: 0.0090\n",
            "Epoch 52/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0086 - val_loss: 0.0088\n",
            "Epoch 53/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0084 - val_loss: 0.0086\n",
            "Epoch 54/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0082 - val_loss: 0.0084\n",
            "Epoch 55/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0080 - val_loss: 0.0082\n",
            "Epoch 56/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0078 - val_loss: 0.0080\n",
            "Epoch 57/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 58/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0075 - val_loss: 0.0077\n",
            "Epoch 59/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0076\n",
            "Epoch 60/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0072 - val_loss: 0.0074\n",
            "Epoch 61/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0071 - val_loss: 0.0073\n",
            "Epoch 62/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0069 - val_loss: 0.0072\n",
            "Epoch 63/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0068 - val_loss: 0.0070\n",
            "Epoch 64/300\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "Epoch 65/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0066 - val_loss: 0.0068\n",
            "Epoch 66/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 67/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0064 - val_loss: 0.0066\n",
            "Epoch 68/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0063 - val_loss: 0.0065\n",
            "Epoch 69/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0062 - val_loss: 0.0064\n",
            "Epoch 70/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0061 - val_loss: 0.0064\n",
            "Epoch 71/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 72/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0062\n",
            "Epoch 73/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0058 - val_loss: 0.0061\n",
            "Epoch 74/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 75/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0057 - val_loss: 0.0060\n",
            "Epoch 76/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 77/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 78/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 79/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0054 - val_loss: 0.0057\n",
            "Epoch 80/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0053 - val_loss: 0.0056\n",
            "Epoch 81/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0053 - val_loss: 0.0056\n",
            "Epoch 82/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0052 - val_loss: 0.0055\n",
            "Epoch 83/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0052 - val_loss: 0.0055\n",
            "Epoch 84/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0051 - val_loss: 0.0054\n",
            "Epoch 85/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0054\n",
            "Epoch 86/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0050 - val_loss: 0.0053\n",
            "Epoch 87/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 88/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 89/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0052\n",
            "Epoch 90/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0048 - val_loss: 0.0051\n",
            "Epoch 91/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0051\n",
            "Epoch 92/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 93/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 94/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0046 - val_loss: 0.0049\n",
            "Epoch 95/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0046 - val_loss: 0.0049\n",
            "Epoch 96/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0045 - val_loss: 0.0048\n",
            "Epoch 97/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0045 - val_loss: 0.0048\n",
            "Epoch 98/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 99/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0044 - val_loss: 0.0047\n",
            "Epoch 100/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0044 - val_loss: 0.0047\n",
            "Epoch 101/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0047\n",
            "Epoch 102/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0043 - val_loss: 0.0046\n",
            "Epoch 103/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0042 - val_loss: 0.0046\n",
            "Epoch 104/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0042 - val_loss: 0.0045\n",
            "Epoch 105/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0042 - val_loss: 0.0045\n",
            "Epoch 106/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0045\n",
            "Epoch 107/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0044\n",
            "Epoch 108/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0044\n",
            "Epoch 109/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0040 - val_loss: 0.0044\n",
            "Epoch 110/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 111/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0040 - val_loss: 0.0043\n",
            "Epoch 112/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 113/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0043\n",
            "Epoch 114/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0042\n",
            "Epoch 115/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0042\n",
            "Epoch 116/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.0042\n",
            "Epoch 117/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0041\n",
            "Epoch 118/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0041\n",
            "Epoch 119/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 120/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0041\n",
            "Epoch 121/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 122/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0040\n",
            "Epoch 123/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 124/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 125/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 126/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0039\n",
            "Epoch 127/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 128/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 129/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 130/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0038\n",
            "Epoch 131/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0034 - val_loss: 0.0038\n",
            "Epoch 132/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 133/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 134/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0034 - val_loss: 0.0037\n",
            "Epoch 135/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 136/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - val_loss: 0.0037\n",
            "Epoch 137/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 138/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0033 - val_loss: 0.0036\n",
            "Epoch 139/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 140/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 141/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0036\n",
            "Epoch 142/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 143/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0032 - val_loss: 0.0035\n",
            "Epoch 144/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 145/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0031 - val_loss: 0.0035\n",
            "Epoch 146/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 147/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.0034\n",
            "Epoch 148/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 149/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 150/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0034\n",
            "Epoch 151/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 152/300\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.0030 - val_loss: 0.0033\n",
            "Epoch 153/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 154/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0033\n",
            "Epoch 155/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 156/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 157/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0029 - val_loss: 0.0032\n",
            "Epoch 158/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 159/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 160/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 161/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 162/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 163/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 164/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0027 - val_loss: 0.0031\n",
            "Epoch 165/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 166/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 167/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 168/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 169/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0026 - val_loss: 0.0030\n",
            "Epoch 170/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.0030\n",
            "Epoch 171/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 172/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 173/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0026 - val_loss: 0.0029\n",
            "Epoch 174/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 175/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 176/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0029\n",
            "Epoch 177/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 178/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 179/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 180/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0025 - val_loss: 0.0028\n",
            "Epoch 181/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 182/300\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 183/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 184/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 185/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 186/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0024 - val_loss: 0.0027\n",
            "Epoch 187/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 188/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0023 - val_loss: 0.0027\n",
            "Epoch 189/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 190/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 191/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 192/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 193/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 194/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0023 - val_loss: 0.0026\n",
            "Epoch 195/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0022 - val_loss: 0.0026\n",
            "Epoch 196/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 197/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 198/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 199/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 200/300\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 201/300\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0022 - val_loss: 0.0025\n",
            "Epoch 202/300\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 203/300\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0021 - val_loss: 0.0025\n",
            "Epoch 204/300\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 205/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 206/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 207/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 208/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 209/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 210/300\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0021 - val_loss: 0.0024\n",
            "Epoch 211/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.0024\n",
            "Epoch 212/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 213/300\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 214/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 215/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 216/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 217/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 218/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 219/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.0023\n",
            "Epoch 220/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 221/300\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 222/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 223/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 224/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 225/300\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 226/300\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 227/300\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 228/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 229/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.0021\n",
            "Epoch 230/300\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 231/300\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 232/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 233/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 234/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 235/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 236/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 237/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 238/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 239/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 240/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 241/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 242/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 243/300\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 244/300\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 245/300\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 246/300\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 247/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 248/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 249/300\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 250/300\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 251/300\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 252/300\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 253/300\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0017 - val_loss: 0.0019\n",
            "Epoch 254/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 255/300\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 256/300\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 257/300\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 258/300\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 259/300\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 260/300\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 261/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 262/300\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 263/300\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 264/300\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 265/300\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 266/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 267/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0016 - val_loss: 0.0018\n",
            "Epoch 268/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 269/300\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 270/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 271/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 272/300\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 273/300\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 274/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 275/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 276/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 277/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 278/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 279/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 280/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 281/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 282/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 283/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 284/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 285/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 286/300\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 287/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 288/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 289/300\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 290/300\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 291/300\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 292/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 293/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 294/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 295/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 296/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 297/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 298/300\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 299/300\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 300/300\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.0014 - val_loss: 0.0016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_encoder = Model(x, h)\n",
        "encoded_imgs = conv_encoder.predict(X_test)\n",
        "\n",
        "n = 1\n",
        "plt.figure(figsize=(28, 10))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(4, 16).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "QLmpqHMBevu5",
        "outputId": "f6d81989-23e2-4574-8270-7f2b5af208b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExA7kO63eyvD",
        "outputId": "642c017b-b401-4242-84fd-b77eb38c28ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "plt.figure(figsize=(28, 28))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    plt.imshow(X_test[i].reshape(28, 28),cmap=\"gist_earth\")\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "SSiPSKeNfgce",
        "outputId": "a8c12340-4b0e-4eba-be5d-965e96397b7a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(28,28))\n",
        "for i in range(n):    \n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(3, n, i+n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap=\"gist_earth\")\n",
        "    # plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "tOLD93oKgHb3",
        "outputId": "6a98ebbe-3682-4460-fbce-13ac1f4b6a9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x2016 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "pJ9a9Kp2fiPO",
        "outputId": "4ae1bd01-7d95-4f73-a426-f6a3e6882496"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'val_loss'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtDklEQVR4nO3deZxcdZ3v/9enqvc1vUI2s7BmISFJE3AYEEUZQAFRkDio4FVxvHIZH+rcG2dGZbjO/eG9DqAzGRUFB5cRmDho5hrkygA6jIBJEAIhQAIkpLN3d3pJeq2qz++PczpUmupOd9Onq7vr/Xw86lGnvud7qj6nK+l3n+17zN0REREZKJbtAkREZGJSQIiISEYKCBERyUgBISIiGSkgREQkIwWEiIhkpIAQGQNm9k9m9rVh9t1hZu9+q+8jEjUFhIiIZKSAEBGRjBQQkjPCXTt/YWabzeyImd1lZieY2YNm1mFmD5tZVVr/y81si5m1mtljZrYgbd4yM3s6XO4+oGjAZ73PzJ4Jl/2dmS0ZZc2fMrPtZtZiZuvMbEbYbmZ2u5kdMLN2M3vOzBaH8y41sxfC2nab2RdH9QOTnKeAkFzzQeA9wKnAZcCDwF8CdQT/H24CMLNTgZ8CnwvnrQf+zcwKzKwA+DnwI6Aa+JfwfQmXXQbcDXwaqAG+C6wzs8KRFGpm7wL+P+BDwHRgJ3BvOPsi4PxwPSrDPs3hvLuAT7t7ObAYeGQknyvSTwEhuebv3X2/u+8G/gN4yt3/4O7dwAPAsrDfNcAv3f3X7t4HfAMoBv4IOAfIB+5w9z53XwtsSPuMG4DvuvtT7p5093uAnnC5kbgWuNvdn3b3HuBLwNvNbC7QB5QDpwPm7lvdfW+4XB+w0Mwq3P2Quz89ws8VARQQknv2p013ZXhdFk7PIPiLHQB3TwG7gJnhvN1+7EiXO9Om5wBfCHcvtZpZKzA7XG4kBtZwmGArYaa7PwL8A7AGOGBmd5pZRdj1g8ClwE4z+42ZvX2EnysCKCBEBrOH4Bc9EOzzJ/glvxvYC8wM2/q9LW16F/C37j4t7VHi7j99izWUEuyy2g3g7t9y9xXAQoJdTX8Rtm9w9yuAeoJdYfeP8HNFAAWEyGDuB95rZheaWT7wBYLdRL8DngASwE1mlm9mHwBWpi37PeDPzOzs8GByqZm918zKR1jDT4GPm9mZ4fGL/0WwS2yHmZ0Vvn8+cAToBlLhMZJrzawy3DXWDqTews9BcpgCQiQDd38J+Ajw90ATwQHty9y91917gQ8A1wMtBMcr/jVt2Y3Apwh2AR0Ctod9R1rDw8CXgZ8RbLWcBKwKZ1cQBNEhgt1QzcD/Ced9FNhhZu3AnxEcyxAZMdMNg0REJBNtQYiISEYKCBERyUgBISIiGSkgREQko7xsFzBWamtrfe7cudkuQ0RkUtm0aVOTu9dlmjdlAmLu3Lls3Lgx22WIiEwqZrZzsHnaxSQiIhkpIEREJCMFhIiIZBTpMQgzuxj4JhAHvu/utw6Yfz5wB7AEWBUOm4yZnQl8m2A4gSTBwGf3RVmriEwsfX19NDY20t3dne1SpoSioiJmzZpFfn7+sJeJLCDMLE4wFPF7gEZgg5mtc/cX0rq9TjBGzcA7XnUCH3P3beEdtDaZ2UPu3hpVvSIysTQ2NlJeXs7cuXM5duBcGSl3p7m5mcbGRubNmzfs5aLcxbQS2O7ur4aDm90LXJHewd13uPtmBow26e4vu/u2cHoPcIDgrl4ikiO6u7upqalROIwBM6OmpmbEW2NRBsRMgnHx+zWGbSNiZiuBAuCVDPNuMLONZrbx4MGDoy5URCYmhcPYGc3PckIfpDaz6QT3/f14eEevY7j7ne7e4O4NdXWj28Bo6+zjmw9v49ldrW+tWBGRKSbKgNhNcAeufrPCtmEJb5/4S+Cv3P3JMa7tjc+Jwe0Pv8yTrzYfv7OI5IzW1lb+8R//ccTLXXrppbS2to59QVkQZUBsAE4xs3lmVkBwo5N1w1kw7P8A8MP+M5uiUlGUT1VJPq+3dEb5MSIyyQwWEIlEYsjl1q9fz7Rp0yKqanxFFhDungBuBB4CtgL3u/sWM7vFzC4HCG+b2AhcDXzXzLaEi38IOB+43syeCR9nRlXr26pLFBAicozVq1fzyiuvcOaZZ3LWWWdx3nnncfnll7Nw4UIA3v/+97NixQoWLVrEnXfeeXS5uXPn0tTUxI4dO1iwYAGf+tSnWLRoERdddBFdXV3ZWp1RifQ6CHdfD6wf0PaVtOkNBLueBi73Y+DHUdaWbnZ1Cc/tbhuvjxOREfqbf9vCC3vax/Q9F86o4KuXLRp0/q233srzzz/PM888w2OPPcZ73/tenn/++aOnid59991UV1fT1dXFWWedxQc/+EFqamqOeY9t27bx05/+lO9973t86EMf4mc/+xkf+chHxnQ9ojShD1KPl7dVl7D7UBeJpO7tLiKZrVy58phrCL71rW+xdOlSzjnnHHbt2sW2bdvetMy8efM488wzAVixYgU7duwYp2rHxpQZzfWtmFNTQiLl7G3rZnZ1SbbLEZEBhvpLf7yUlpYenX7sscd4+OGHeeKJJygpKeGCCy7IeI1BYWHh0el4PD7pdjFpC6JjH+/93TVcGnuSXToOISKh8vJyOjo6Ms5ra2ujqqqKkpISXnzxRZ58MrITLbNKWxDF1ZS2vsTpsVPZ2dLJH2W7HhGZEGpqajj33HNZvHgxxcXFnHDCCUfnXXzxxXznO99hwYIFnHbaaZxzzjlZrDQ6Coi8Aqiaw8lNe3lOWxAikuaf//mfM7YXFhby4IMPZpzXf5yhtraW559//mj7F784cMi5iU+7mACrOZnT8vbrVFcRkTQKCICaU5jle2lsPpztSkREJgwFBEDtyRR6D70tu47fV0QkRyggAGpOAaC253XauvqyXIyIyMSggACoDQJinu3Vqa4iIiEFBEBpPalYATOsRQeqRURCCgiAWAwqZjDdmrUFISKjUlZWBsCePXu46qqrMva54IIL2Lhx45Dvc8cdd9DZ+cbvoWwOH66ACMUqZzIzdoh97bpBuoiM3owZM1i7dvR3KRgYENkcPlwB0a9iJjNjzRxo78l2JSIyAaxevZo1a9YcfX3zzTfzta99jQsvvJDly5dzxhln8Itf/OJNy+3YsYPFixcD0NXVxapVq1iwYAFXXnnlMWMxfeYzn6GhoYFFixbx1a9+FQgGANyzZw/vfOc7eec73wm8MXw4wG233cbixYtZvHgxd9xxx9HPi2pYcV1J3a9iBnXewoE27WISmXAeXA37nhvb9zzxDLjk1kFnX3PNNXzuc5/js5/9LAD3338/Dz30EDfddBMVFRU0NTVxzjnncPnllw96v+dvf/vblJSUsHXrVjZv3szy5cuPzvvbv/1bqqurSSaTXHjhhWzevJmbbrqJ2267jUcffZTa2tpj3mvTpk384Ac/4KmnnsLdOfvss3nHO95BVVVVZMOKawuiX+Us8kjQ27E/25WIyASwbNkyDhw4wJ49e3j22WepqqrixBNP5C//8i9ZsmQJ7373u9m9ezf79w/+O+O3v/3t0V/US5YsYcmSJUfn3X///Sxfvpxly5axZcsWXnjhhSHrefzxx7nyyispLS2lrKyMD3zgA/zHf/wHEN2w4tqC6FcxA4B4x17cfdC/CEQkC4b4Sz9KV199NWvXrmXfvn1cc801/OQnP+HgwYNs2rSJ/Px85s6dm3GY7+N57bXX+MY3vsGGDRuoqqri+uuvH9X79ItqWHFtQfSrmAlAXaqJ1k5dLCciwW6me++9l7Vr13L11VfT1tZGfX09+fn5PProo+zcuXPI5c8///yjA/49//zzbN68GYD29nZKS0uprKxk//79xwz8N9gw4+eddx4///nP6ezs5MiRIzzwwAOcd955Y7i2b6YtiH5hQJxoLezv6KaqtCDLBYlIti1atIiOjg5mzpzJ9OnTufbaa7nssss444wzaGho4PTTTx9y+c985jN8/OMfZ8GCBSxYsIAVK1YAsHTpUpYtW8bpp5/O7NmzOffcc48uc8MNN3DxxRczY8YMHn300aPty5cv5/rrr2flypUAfPKTn2TZsmWR3qXO3D2yNx9PDQ0Nfrzzi4eUSuH/s5Y1fe/jjI/9He84tW7sihOREdu6dSsLFizIdhlTSqafqZltcveGTP21i6lfLEaqpJZa2tivayFERBQQ6aysnlpr44ACQkREAZEuVlbPCfF2mg73ZrsUEQGmyi7wiWA0P0sFRLrSOuqsneYjCgiRbCsqKqK5uVkhMQbcnebmZoqKika0nM5iSldWR5W30dyhXUwi2TZr1iwaGxs5ePBgtkuZEoqKipg1a9aIlok0IMzsYuCbQBz4vrvfOmD++cAdwBJglbuvTZt3HfDX4cuvufs9UdYKQGk9hfTSdbgt8o8SkaHl5+czb968bJeR0yLbxWRmcWANcAmwEPiwmS0c0O114HrgnwcsWw18FTgbWAl81cyqoqr1qLL64PnIgcg/SkRkoovyGMRKYLu7v+ruvcC9wBXpHdx9h7tvBlIDlv0T4Nfu3uLuh4BfAxdHWGugNLj2Ib/rIMmU9nuKSG6LMiBmArvSXjeGbWO2rJndYGYbzWzjmOynDLcgqmmntVMHqkUkt03qs5jc/U53b3D3hrq6MbjyOdyCqLU2nckkIjkvyoDYDcxOez0rbIt62dErqcUx6qyNpsO6cZCI5LYoA2IDcIqZzTOzAmAVsG6Yyz4EXGRmVeHB6YvCtmjF80gWVVFDG826WE5EclxkAeHuCeBGgl/sW4H73X2Lmd1iZpcDmNlZZtYIXA1818y2hMu2AP+TIGQ2ALeEbdErq6fW2mnWFoSI5LhIr4Nw9/XA+gFtX0mb3kCw+yjTsncDd0dZXybxsnpqD+xji45BiEiOm9QHqaNgZfWcENN4TCIiCoiByurDYxDaxSQiuU0BMVBpLSV00XG4PduViIhklQJioNLgYjnv0HAbIpLbFBADhVdTxzqbslyIiEh2KSAGCq+mLulrobsvmeViRESyRwExULgFUWtttOhUVxHJYQqIgfrHY9LV1CKS4xQQA+UVkigop9baaDqiU11FJHcpIDLwkvpgRFdtQYhIDlNAZBAr13hMIiIKiAxi5fXU6Z4QIpLjFBAZWGk9ddaue0KISE5TQGRSVk8Fh2ntOJLtSkREskYBkUl4qmtSw22ISA5TQGQSBoQdOZjlQkREskcBkUl4NXV+VxPunuViRESyQwGRSbgFUemtdPQkslyMiEh2KCAy6R+PScNtiEgOU0BkUlBKMq8kvJpap7qKSG5SQAwiWVwbjMekgBCRHKWAGExZHbW00aRdTCKSoxQQg8grPyEcj0kBISK5SQExiFh5PXWxdpo15LeI5KhIA8LMLjazl8xsu5mtzjC/0MzuC+c/ZWZzw/Z8M7vHzJ4zs61m9qUo68yotJ5pdNDS0TXuHy0iMhFEFhBmFgfWAJcAC4EPm9nCAd0+ARxy95OB24Gvh+1XA4XufgawAvh0f3iMm7J64qTobdfV1CKSm6LcglgJbHf3V929F7gXuGJAnyuAe8LptcCFZmaAA6VmlgcUA71Ae4S1vll4sZwf0XhMIpKbogyImcCutNeNYVvGPu6eANqAGoKwOALsBV4HvuHuLQM/wMxuMLONZrbx4MEx/ks/vFgu3qktCBHJTRP1IPVKIAnMAOYBXzCz+QM7ufud7t7g7g11dXVjW0G4BVHU00IimRrb9xYRmQSiDIjdwOy017PCtox9wt1JlUAz8KfAr9y9z90PAP8JNERY65uFAVFrbbR06lRXEck9UQbEBuAUM5tnZgXAKmDdgD7rgOvC6auARzwYPvV14F0AZlYKnAO8GGGtb1ZUSSqWr2shRCRnRRYQ4TGFG4GHgK3A/e6+xcxuMbPLw253ATVmth34PNB/KuwaoMzMthAEzQ/cfXNUtWZkRl9xXTgekwJCRHJPXpRv7u7rgfUD2r6SNt1NcErrwOUOZ2ofb15aR217my6WE5GcNFEPUk8I8bL6cMA+bUGISO5RQAwhr6JeI7qKSM5SQAzByuqptXYOtHVmuxQRkXGngBhKaT15JDnc2pTtSkRExp0CYijh1dQ9bfuzXIiIyPhTQAylfzymwwcILs8QEckdCoihhFsQ5YlDtHcnslyMiMj4UkAMpTQIiFprY397d5aLEREZXwqIoRRX4Ran1trY26aAEJHcooAYSixGsvQEplsL+9p0ZzkRyS0KiOOITZvFdJq1BSEiOUcBcRyxabOZHW/RMQgRyTkKiOOpmMkJNLOvVVdTi0huUUAcT+VsCuijq1UXy4lIblFAHE/lLADiHQNvhiciMrUpII6nciYAZT376epNZrkYEZHxo4A4nsrgttozrZl9OlAtIjlEAXE8xVUk40VMt2b26loIEckhCojjMSNZPpMZ1qRTXUUkpygghiFeNZuZpovlRCS3KCCGIT5tFjNiLextVUCISO5QQAxH5WxqaWVPS1u2KxERGTfDCggz+3Mzq7DAXWb2tJldFHVxE0bFTGI4XU2N2a5ERGTcDHcL4r+4eztwEVAFfBS4NbKqJprwYjlrbySZ0p3lRCQ3DDcgLHy+FPiRu29Ja5v6wmsh6lMHdSaTiOSM4QbEJjP7fwQB8ZCZlQOp4y1kZheb2Utmtt3MVmeYX2hm94XznzKzuWnzlpjZE2a2xcyeM7OiYdY69ipmADDdmnm9RYP2iUhuGG5AfAJYDZzl7p1APvDxoRYwsziwBrgEWAh82MwWZnjfQ+5+MnA78PVw2Tzgx8Cfufsi4AKgb5i1jr2CEpJF1cyyg7zerIAQkdww3IB4O/CSu7ea2UeAvwaOd0rPSmC7u7/q7r3AvcAVA/pcAdwTTq8FLjQzIzjWsdndnwVw92Z3z+pASLGak5gbO6AtCBHJGcMNiG8DnWa2FPgC8Arww+MsMxPYlfa6MWzL2MfdEwShUwOcCriZPRSeMfXfM32Amd1gZhvNbOPBgweHuSqjYzXzmR9XQIhI7hhuQCTc3Qn+4v8Hd18DlEdXFnnAHwPXhs9XmtmFAzu5+53u3uDuDXV1dRGWA1TPp96b2NvcGu3niIhMEMMNiA4z+xLB6a2/NLMYwXGIoewGZqe9nhW2ZewTHneoBJoJtjZ+6+5N4TGP9cDyYdYajer5xHBSLTuyWoaIyHgZbkBcA/QQXA+xj+CX/f85zjIbgFPMbJ6ZFQCrgHUD+qwDrgunrwIeCbdUHgLOMLOSMDjeAbwwzFqjUT0fgGndu+jozt7xchGR8TKsgAhD4SdApZm9D+h29yGPQYTHFG4k+GW/Fbjf3beY2S1mdnnY7S6gxsy2A58nOFMKdz8E3EYQMs8AT7v7L0e6cmMqDIi5tp9dLRr2W0SmvrzhdDKzDxFsMTxGcIHc35vZX7j72qGWc/f1BLuH0tu+kjbdDVw9yLI/JjjVdWIoriJZUMGcxH5eb+lk4YyKbFckIhKpYQUE8FcE10AcADCzOuBhglNTc4MZVM9nbtc+Xmw5ku1qREQiN9xjELH+cAg1j2DZKSNeexLz4gfYqYvlRCQHDHcL4ldm9hDw0/D1NQzYdZQTquczgwfYceBQtisREYncsALC3f/CzD4InBs23enuD0RX1gRVPZ84KToP7ADOz3Y1IiKRGu4WBO7+M+BnEdYy8YVnMlV27aLlSC/VpQVZLkhEJDpDHkcwsw4za8/w6DCz9vEqcsKoPgmAObafbfs7slyMiEi0htyCcPcoh9OYfEprSRWUMTexj20HDnP2/JpsVyQiEpmcOxPpLTHDak/l9PgebUGIyJSngBghq1/AafFGth04nO1SREQipYAYqfoFVKcOcWD/nmxXIiISKQXESNUvAKDmyKu0dvZmuRgRkegoIEaqPrhr6qmxXdrNJCJTmgJipMqnkyqs5FRrZNt+BYSITF0KiJEyw+oXsiDeyMs6k0lEpjAFxCjYCQs4LdbIS3tz71pBEckdCojRqFtAuR/m4N6dBDfAExGZehQQoxGeyTS99zX2tHVnuRgRkWgoIEYjDIhTbRdbdrdluRgRkWgoIEajtBYvref02C5e0HEIEZmiFBCjZCeewZn5u3hhjwJCRKYmBcRoTV/K/NTrbNvTnO1KREQioYAYrelLiJOktO1l2rr6sl2NiMiYU0CM1vSlACyO7dBuJhGZkhQQo1U1j1RhBYvtNR2oFpEpSQExWmbEpi/lzPzX2bJHp7qKyNQTaUCY2cVm9pKZbTez1RnmF5rZfeH8p8xs7oD5bzOzw2b2xSjrHLXpSznNd/DCLh2oFpGpJ7KAMLM4sAa4BFgIfNjMFg7o9gngkLufDNwOfH3A/NuAB6Oq8S2bvpR8+qD5ZQ73JLJdjYjImIpyC2IlsN3dX3X3XuBe4IoBfa4A7gmn1wIXmpkBmNn7gdeALRHW+NaEB6oXsYPnGrWbSUSmligDYiawK+11Y9iWsY+7J4A2oMbMyoD/AfzNUB9gZjeY2UYz23jw4MExK3zYak7G80tYHHuNZxtbx//zRUQiNFEPUt8M3O7uQ96Rx93vdPcGd2+oq6sbn8rSxeLY9KWsLNjBs7tax//zRUQilBfhe+8GZqe9nhW2ZerTaGZ5QCXQDJwNXGVm/xuYBqTMrNvd/yHCekdn9kpOe30NW18/kO1KRETGVJRbEBuAU8xsnpkVAKuAdQP6rAOuC6evAh7xwHnuPtfd5wJ3AP9rQoYDwOyzySNBTcdWDrRr6G8RmToiC4jwmMKNwEPAVuB+d99iZreY2eVht7sIjjlsBz4PvOlU2Alv1koAVsRe5lkdqBaRKSTKXUy4+3pg/YC2r6RNdwNXH+c9bo6kuLFSVkeq+iQamrbx7K5W3rPwhGxXJCIyJibqQepJJTb7bFbGt/H0zpZslyIiMmYUEGNh9kqmeRtNu16kJ5HMdjUiImNCATEWZp8NwOLki2zWcQgRmSIUEGOh7nS8sIKG+Ms8+YrGZRKRqUEBMRZiMextb+f8/Jd44lUFhIhMDQqIsXLSO5mV2s2+nS/pOISITAkKiLFy0rsAWOmbeXaXjkOIyOSngBgrtaeSKp/B+bHNPKHjECIyBSggxooZsZPfxfl5W/jd9v3ZrkZE5C1TQIylk95FmR+hb9fTtHX2ZbsaEZG3RAExluZdgGOcy7P8ZlsW7k8hIjKGFBBjqbQGZpzJe/I38+9btZtJRCY3BcQYs9PfxxJe5sUXXyCRTGW7HBGRUVNAjLXFHwDg/L7H2bjzUJaLEREZPQXEWKueT/LEpVwWf1K7mURkUlNARCB+xlUsib3Kc889g7tnuxwRkVFRQERh0ZUALO94jE3azSQik5QCIgrTZpOceRZX5v0n//p0Y7arEREZFQVEROIN13OKNbJv88MavE9EJiUFRFQWf5C+gmlclXyQR7YeyHY1IiIjpoCISn4x8RUf46L4Rh75/R+yXY2IyIgpICIUW/lJ4jhzXruPXS2d2S5HRGREFBBRqppDz0l/wrXxh/nJb5/LdjUiIiOigIhY0YVfosoOU/6HO2nr0givIjJ5RBoQZnaxmb1kZtvNbHWG+YVmdl84/ykzmxu2v8fMNpnZc+Hzu6KsM1IzzqRt3iVcx//l548/m+1qRESGLbKAMLM4sAa4BFgIfNjMFg7o9gngkLufDNwOfD1sbwIuc/czgOuAH0VV53iovORmSqyH+BPfpLM3ke1yRESGJcotiJXAdnd/1d17gXuBKwb0uQK4J5xeC1xoZubuf3D3PWH7FqDYzAojrDVa9afTcvIHuDq5nvsefCTb1YiIDEuUATET2JX2ujFsy9jH3RNAG1AzoM8HgafdvSeiOsdF7ftvJREvZvHTX2bPoSPZLkdE5Lgm9EFqM1tEsNvp04PMv8HMNprZxoMHJ/gd3Mrq6XnX33CWvchv7rst29WIiBxXlAGxG5id9npW2Jaxj5nlAZVAc/h6FvAA8DF3fyXTB7j7ne7e4O4NdXV1Y1z+2Ks+97+wq2IF79u7hseffCLb5YiIDCnKgNgAnGJm88ysAFgFrBvQZx3BQWiAq4BH3N3NbBrwS2C1u/9nhDWOLzNOuO4HpGL5TP/VJznY3JztikREBhVZQITHFG4EHgK2Ave7+xYzu8XMLg+73QXUmNl24PNA/6mwNwInA18xs2fCR31UtY6ngpo5dLzvTub6bl77/nUkkxrIT0QmJpsqN7RpaGjwjRs3ZruMYdt07y2sePHv2Fj7fho++09glu2SRCQHmdkmd2/ING9CH6SeylZc82UeP/GjNDT9nOd/cCNMkaAWkalDAZEtZrz9U9/i4YorWfz6j3n1+9dBUkNxiMjEoYDIong8xh/f+H0eqPwY83f/gt3/eDl06RalIjIxKCCyrKggj0v/2x3cU/t56pqe4tAd55LcozGbRCT7FBATQGFenD/9zJf5walr6O7uIvm9d9P55D/puISIZJUCYoLIj8e44U9X8dgFa9mQPJWSX/05h+66Ctr3Zrs0EclRCogJxMz48DtXUPaJdawp+DjFu35D9zfPom/Tj7Q1ISLjTgExAS2dU8P1X/gGd5zyTzzbN5P8f7uRljsvg4MvZ7s0EckhCogJqrQwj9UfeR/d167jmwWfIn/PRpJrzqZj7X+Djv3ZLk9EcoCupJ4EuvuS/OjhTRQ98Xessl+TiheQOPuzlJ5/IxRXZbs8EZnEhrqSWgExiexv7+bH6x9l4Qu3c0nsKXpjxfQsuZbyd9wEVXOyXZ6ITEIKiClmR9MRfvbgr5i/7Qe8z35H3JzWuZdS9Y5PY3PP07hOIjJsCogpam9bF2sf/T2lf/g+V/EwFdZJe/Fs4is+SunyD0H1vGyXKCITnAJiijvSk+DBP7zCrsfv4+3t6zknthWAQxWnUbD4CkqXXgn1C7RlISJvooDIIS/ua+e3T22id8s6zu5+nBW2jZg5Hfm19Mw4h8oFF5A//zyoO02BISIKiFzk7mzZ086G516gd+t6prdsZGVsKydaMBjgkbwqOmuXUPS2ZZTNWYZNXwrT5kBMZz6L5BIFhNDR3ceTrzSz/aXnSO14nOmtT7OQ1zjZdpNnKQB6Y0UcKZsLNadQOuN0Ck48HWpODh6FZdldARGJhAJC3qS7L8mWPW28tOsAh3ZuJrZvMyXtr/C21G7m215m20Fi9sa/jSP5NfSVTofKmRRUz6aodg6xyllQOQsqZkBpHeQVZnGNRGQ0FBAyLKmUs+tQJ1v3drBzfzNH9m7Dm7ZR0vEq03r2MsOamWHNTLdmyqz7Tcv35FXQV1xLqqQeK6+noHI6BZUnYOUnBAFSXAXF1cFzUSXE87KwliKSbqiA0P9QOSoWM+bUlDKnphQWnwgsOjqvszfBzuZOdh7q4snWTppbmuhueh1v3UXsyD7yu5qoSbRS29NGXdshavfuoM7aKLSuQT+vN6+cRGElqaIqKK4iXlpNflkNeaVhiBSWpz0qjn1dUAax+Dj8VERylwJChqWkII8F0ytYML0ibJkHnHV0fjLltBzppelwD02He3j2cA9NHb20trXR07aPZMcBkkdaoOsQ8Z5WKvww0xKHmdZzmGnth5lme6jkZabZYSo5QtyOv2WbiBeTyC8jVVCOF5RjReXEiiqIF1eQV1yBFZZDQSnkl0B+MeSXhs/FYXtx2ryS4JFXqLO7REIKCBkT8ZhRV15IXfnxj0O4O529SVq7+mjt7KWts4+9XX1s7eyjtauXtiM9dB9upedIK4nOdujtwHoOE+vrIK/vMEWpTsrooizRRVlPF2XWFby2A5Sxk/L+13QdPQA/XCliJONFpPKKSeUV43nFeH4Jll+MFZQQKywlVlBCXmEpVlDyRsAUlEJeUfgogHhhEDZ5hUFbvOCNece8LtSWkExYCggZd2ZGaWEepYV5zJxWPOLlexMpjvQkONyToKM7wZHeBIe7E+ztCZ4P9/RxuDtBZ0+Cnt5uUj2dJHuOkOrtxHs78b5OYn2dWF8XsWQXsUQX+aluiuml2LopTvRS3NNDsfUEbfRQYq0UcSCc7qEobC+2XmK8teN4KcsjFSsgFS+EeAGeV3g0YCyvEPKLiOUVEssvwvILsWPCp79vpvDpf52pf4bw0jEhGUD/ImTSKciLUZBXQFVpwZi9ZyrldPUlg0dv8NzZ2z+d4GDvG+1dvcG87r4knT0J+nq78L4gfFJ9PXhfN57ogUQ3JHoh0Y2lerFED5bsoYA+CuijkD4KSFBovcFzf7v1hX0SFNJLoR15oy+9FFiCIvoosPA1fW85pCDYegqCquBoYKXiBXi8EI8VBAESy8Pi+cFzLA/i+cTieVg8aLd4HrF4QficRyzsS9iXWDx8HbaH7/lGWzytb174On/w5WPxtL6Zls/TLsO3QAEhQnCAvn+rJmp9yRQ9iRTdfcmjz+nTPYkUPX1JOhMpWtLaexMpehMpepLBc1/43NuXJJHsw/t6SIXhZIkeSAaBRKKHWLIHS/ZiqV5iyR7iqd5jQigIqvTgCoKqMC24YvSSb13ESZJPkjhJ8kiRd3Q6SZ4Fbel9+p+Hc1wpCinipCyOW5xULC+czsdjYXssH7c4HoZRMB2Eiw8Mnlh+GGpxLC3kLBbP+IjF4lgsD4vFiMUz97FYHCwOFgs+x+LhcyxDWzwIvIFtheVwwsIx/9lF+r/BzC4GvgnEge+7+60D5hcCPwRWAM3ANe6+I5z3JeATQBK4yd0firJWkfGSH4+RH49RNg5hNJRUyulLpUgknUTS6U2mSISv+5IpEimnNxE8J5Ip+pJB/85wOpF0EqmwPZk62qe/rf99+j8jmUiQTCZIJvpIJRN4spdUIoGnEpDqw5MJLJWAVALzYNpSCfAklgzbPEks1Rc8exJL9WGeIu7B/JgniR19ThInQZxUWqAl0wItFQZaepClyCdBnB7yrPPYvmnL5lvQN49EGIgpYqSI4Uen46SOuZYoSq8VLWDe6ifH/H0j+xdqZnFgDfAeoBHYYGbr3P2FtG6fAA65+8lmtgr4OnCNmS0EVhGcZzkDeNjMTnX3ZFT1iuSaWMwojMXJck5Fyt1JeXCWXcqdRMqD6VQwnfLgdf8jU1vSna4ByyU97T3C18cs098nmSKZSpJKJoNQTKXAE3gyhXsKUgnck3gqCZ6CZPKN16kUHJ2XxDwZLp+CVDJ4eBL3FNVV1UQxdnOU/zRWAtvd/VUAM7sXuAJID4grgJvD6bXAP5iZhe33unsP8JqZbQ/f74kI6xWRKcbMiFtwlp2MXJQjs80EdqW9bgzbMvZx9wTQBtQMc1nM7AYz22hmGw8ePDiGpYuIyKQeutPd73T3BndvqKury3Y5IiJTSpQBsRuYnfZ6VtiWsY+Z5QGVBAerh7OsiIhEKMqA2ACcYmbzzKyA4KDzugF91gHXhdNXAY94MHrgOmCVmRWa2TzgFOD3EdYqIiIDRHaQ2t0TZnYj8BDBaa53u/sWM7sF2Oju64C7gB+FB6FbCEKEsN/9BAe0E8BndQaTiMj40nDfIiI5bKjhvif1QWoREYmOAkJERDKaMruYzOwgsPMtvEUt0DRG5WTbVFmXqbIeoHWZqLQuMMfdM14nMGUC4q0ys42D7YebbKbKukyV9QCty0SldRmadjGJiEhGCggREclIAfGGO7NdwBiaKusyVdYDtC4TldZlCDoGISIiGWkLQkREMlJAiIhIRjkfEGZ2sZm9ZGbbzWx1tusZKTPbYWbPmdkzZrYxbKs2s1+b2bbwuSrbdWZiZneb2QEzez6tLWPtFvhW+D1tNrPl2av8zQZZl5vNbHf43TxjZpemzftSuC4vmdmfZKfqzMxstpk9amYvmNkWM/vzsH1SfTdDrMek+17MrMjMfm9mz4br8jdh+zwzeyqs+b5wYFTCgU7vC9ufMrO5o/pgd8/ZB8Eggq8A84EC4FlgYbbrGuE67ABqB7T9b2B1OL0a+Hq26xyk9vOB5cDzx6sduBR4EDDgHOCpbNc/jHW5Gfhihr4Lw39rhcC88N9gPNvrkFbfdGB5OF0OvBzWPKm+myHWY9J9L+HPtiyczgeeCn/W9wOrwvbvAJ8Jp/8r8J1wehVw32g+N9e3II7eFtXde4H+26JOdlcA94TT9wDvz14pg3P33xKM4ptusNqvAH7ogSeBaWY2fVwKHYZB1mUwR2+p6+6vAf231J0Q3H2vuz8dTncAWwnu6Dipvpsh1mMwE/Z7CX+2h8OX+eHDgXcR3K4Z3vyd9H9Xa4ELw9s5j0iuB8Swbm06wTnw/8xsk5ndELad4O57w+l9wAnZKW1UBqt9sn5XN4a7Xe5O29U3adYl3DWxjOAv1kn73QxYD5iE34uZxc3sGeAA8GuCLZxWD27XDMfWO9jtnEck1wNiKvhjd18OXAJ81szOT5/pwTbmpDyXeTLXHvo2cBJwJrAX+LusVjNCZlYG/Az4nLu3p8+bTN9NhvWYlN+Luyfd/UyCO2yuBE6P+jNzPSAm/a1N3X13+HwAeIDgH87+/k388PlA9iocscFqn3TflbvvD/9Tp4Dv8cbuigm/LmaWT/BL9Sfu/q9h86T7bjKtx2T+XgDcvRV4FHg7we68/hu/pdc72O2cRyTXA2I4t0WdsMys1MzK+6eBi4DnOfZWrtcBv8hOhaMyWO3rgI+FZ8ycA7Sl7e6YkAbsh7+S4LuBCX5L3XBf9V3AVne/LW3WpPpuBluPyfi9mFmdmU0Lp4uB9xAcU3mU4HbN8ObvJNPtnEcm20fns/0gOAPjZYL9eX+V7XpGWPt8grMungW29NdPsK/x34FtwMNAdbZrHaT+nxJs4vcR7D/9xGC1E5zFsSb8np4DGrJd/zDW5UdhrZvD/7DT0/r/VbguLwGXZLv+AevyxwS7jzYDz4SPSyfbdzPEeky67wVYAvwhrPl54Cth+3yCENsO/AtQGLYXha+3h/Pnj+ZzNdSGiIhklOu7mEREZBAKCBERyUgBISIiGSkgREQkIwWEiIhkpIAQmQDM7AIz+7/ZrkMknQJCREQyUkCIjICZfSQcl/8ZM/tuOIDaYTO7PRyn/9/NrC7se6aZPRkOCvdA2v0TTjazh8Ox/Z82s5PCty8zs7Vm9qKZ/WQ0o2+KjCUFhMgwmdkC4BrgXA8GTUsC1wKlwEZ3XwT8BvhquMgPgf/h7ksIrtztb/8JsMbdlwJ/RHAFNgSjjX6O4L4E84FzI14lkSHlHb+LiIQuBFYAG8I/7osJBqxLAfeFfX4M/KuZVQLT3P03Yfs9wL+EY2fNdPcHANy9GyB8v9+7e2P4+hlgLvB45GslMggFhMjwGXCPu3/pmEazLw/oN9rxa3rSppPo/6dkmXYxiQzfvwNXmVk9HL1H8xyC/0f9I2r+KfC4u7cBh8zsvLD9o8BvPLizWaOZvT98j0IzKxnPlRAZLv2FIjJM7v6Cmf01wR38YgQjt34WOAKsDOcdIDhOAcFwy98JA+BV4ONh+0eB75rZLeF7XD2OqyEybBrNVeQtMrPD7l6W7TpExpp2MYmISEbaghARkYy0BSEiIhkpIEREJCMFhIiIZKSAEBGRjBQQIiKS0f8PgH08zZleKwsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "for i in range(n):\n",
        "  print(\"Error or loss for the image \"+str(i))\n",
        "  print(tf.math.reduce_mean(tf.square(decoded_imgs[i].reshape(28, 28)-X_test[i].reshape(28, 28))))\n",
        "  print(\"------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65L7IaM-foed",
        "outputId": "fe9187a1-41ae-4fe5-d905-56effd7da752"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error or loss for the image 0\n",
            "tf.Tensor(0.0021368507, shape=(), dtype=float32)\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbaHstUEr_AA",
        "outputId": "c3a3546a-c5be-4dad-c9d9-27cebb095b66"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir lenia_mods\n",
        "# %cd lenia_mods\n",
        "# autoencoder.save(\"encoder.h5\")"
      ],
      "metadata": {
        "id": "DTW1j9UJ4XHf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# model1 = load_model('autoencoder.h5')"
      ],
      "metadata": {
        "id": "r0DNLWTT4fhE"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}